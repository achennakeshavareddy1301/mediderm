{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP__-padXaPT",
        "outputId": "bffd8498-be36-497a-9842-aad876494baa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Working directory: /content/drive/MyDrive/SkinDiseaseProject\n",
            "‚úÖ Checkpoints are SAFE - not deleted!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CELL 1: Mount Drive & Setup (SAFE VERSION)\n",
        "# ============================================================\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Working directory\n",
        "work_dir = '/content/drive/MyDrive/SkinDiseaseProject'\n",
        "os.makedirs(work_dir, exist_ok=True)\n",
        "os.chdir(work_dir)\n",
        "\n",
        "print(f\"‚úÖ Working directory: {work_dir}\")\n",
        "print(\"‚úÖ Checkpoints are SAFE - not deleted!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAHMtnzlY3No",
        "outputId": "ab464a94-39d4-416a-8b4c-706ebe3b6e7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All dataset paths already exist - skipping download!\n",
            "‚úÖ Checkpoints are safe!\n",
            "   DermNet: /kaggle/input/dermnet\n",
            "   Mgmitesh: /root/.cache/kagglehub/datasets/mgmitesh/skin-disease-detection-dataset/versions/1\n",
            "   Ismailpromus: /root/.cache/kagglehub/datasets/ismailpromus/skin-diseases-image-dataset/versions/1\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CELL 2: Download Datasets (Skip if already exist)\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import kagglehub\n",
        "\n",
        "work_dir = '/content/drive/MyDrive/SkinDiseaseProject'\n",
        "\n",
        "# Check if datasets already exist\n",
        "dermnet_exists = os.path.exists('dermnet_path.txt')\n",
        "mgmitesh_exists = os.path.exists('mgmitesh_path.txt')\n",
        "ismailpromus_exists = os.path.exists('ismailpromus_path.txt')\n",
        "\n",
        "if dermnet_exists and mgmitesh_exists and ismailpromus_exists:\n",
        "    print(\"‚úÖ All dataset paths already exist - skipping download!\")\n",
        "    print(\"‚úÖ Checkpoints are safe!\")\n",
        "\n",
        "    # Read existing paths\n",
        "    with open('dermnet_path.txt', 'r') as f:\n",
        "        print(f\"   DermNet: {f.read().strip()}\")\n",
        "    with open('mgmitesh_path.txt', 'r') as f:\n",
        "        print(f\"   Mgmitesh: {f.read().strip()}\")\n",
        "    with open('ismailpromus_path.txt', 'r') as f:\n",
        "        print(f\"   Ismailpromus: {f.read().strip()}\")\n",
        "else:\n",
        "    print(\"üì• Downloading datasets...\")\n",
        "\n",
        "    # Download DermNet\n",
        "    if not dermnet_exists:\n",
        "        dermnet_path = kagglehub.dataset_download('shubhamgoel27/dermnet')\n",
        "        with open('dermnet_path.txt', 'w') as f:\n",
        "            f.write(dermnet_path)\n",
        "        print(f\"‚úÖ DermNet: {dermnet_path}\")\n",
        "\n",
        "    # Download Mgmitesh\n",
        "    if not mgmitesh_exists:\n",
        "        mgmitesh_path = kagglehub.dataset_download('mgmitesh/skin-disease-detection-dataset')\n",
        "        with open('mgmitesh_path.txt', 'w') as f:\n",
        "            f.write(mgmitesh_path)\n",
        "        print(f\"‚úÖ Mgmitesh: {mgmitesh_path}\")\n",
        "\n",
        "    # Download Ismailpromus\n",
        "    if not ismailpromus_exists:\n",
        "        ismailpromus_path = kagglehub.dataset_download('ismailpromus/skin-diseases-image-dataset')\n",
        "        with open('ismailpromus_path.txt', 'w') as f:\n",
        "            f.write(ismailpromus_path)\n",
        "        print(f\"‚úÖ Ismailpromus: {ismailpromus_path}\")\n",
        "\n",
        "    print(\"\\n‚úÖ All datasets ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8c9e7b6",
        "outputId": "10099018-4510-4349-f956-e8cf947fb35f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì• Attempting to download mgmitesh/skin-disease-detection-dataset using kagglehub...\n",
            "Using Colab cache for faster access to the 'skin-disease-detection-dataset' dataset.\n",
            "‚úÖ Download of mgmitesh/skin-disease-detection-dataset seems successful.\n",
            "Path to dataset files: /kaggle/input/skin-disease-detection-dataset\n",
            "‚úÖ Updated mgmitesh_path.txt with new path: /kaggle/input/skin-disease-detection-dataset\n"
          ]
        }
      ],
      "source": [
        "# Download the Mgmitesh dataset using kagglehub\n",
        "\n",
        "import kagglehub\n",
        "import os\n",
        "\n",
        "# Define the dataset handle\n",
        "mgmitesh_handle = \"mgmitesh/skin-disease-detection-dataset\"\n",
        "work_dir = '/content/drive/MyDrive/SkinDiseaseProject' # Ensure work_dir is defined\n",
        "mgmitesh_path_file = os.path.join(work_dir, 'mgmitesh_path.txt')\n",
        "\n",
        "print(f\"üì• Attempting to download {mgmitesh_handle} using kagglehub...\")\n",
        "\n",
        "try:\n",
        "    # Use kagglehub.dataset_download to download and get the path\n",
        "    local_path = kagglehub.dataset_download(mgmitesh_handle)\n",
        "    print(f\"‚úÖ Download of {mgmitesh_handle} seems successful.\")\n",
        "    print(f\"Path to dataset files: {local_path}\")\n",
        "\n",
        "    # Save the actual local path to the text file\n",
        "    with open(mgmitesh_path_file, 'w') as f:\n",
        "        f.write(local_path)\n",
        "    print(f\"‚úÖ Updated mgmitesh_path.txt with new path: {local_path}\")\n",
        "\n",
        "    # Verify if the path exists\n",
        "    if not os.path.exists(local_path):\n",
        "         print(f\"‚ùå Verified path does NOT exist: {local_path}\")\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error downloading {mgmitesh_handle}: {e}\")\n",
        "    # Optionally, remove the path file if download failed\n",
        "    if os.path.exists(mgmitesh_path_file):\n",
        "        os.remove(mgmitesh_path_file)\n",
        "        print(f\"Removed {mgmitesh_path_file} as download failed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f41a1e72"
      },
      "source": [
        "Now that we've attempted to download the Mgmitesh dataset using the Kaggle API, let's rerun the dataset processing cell to see if it can find and process the data from the new location."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "843c94cb",
        "outputId": "db2e1ee3-50af-4305-d4d2-c493d12f7e5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "================================================================================\n",
            "üì• DOWNLOADING ALL DATASETS\n",
            "================================================================================\n",
            "üóëÔ∏è  Removed old dermnet_path.txt\n",
            "üóëÔ∏è  Removed old mgmitesh_path.txt\n",
            "\n",
            "üì• Downloading datasets (this may take 10-15 minutes)....\n",
            "\n",
            "1Ô∏è‚É£  Downloading DermNet...\n",
            "Using Colab cache for faster access to the 'dermnet' dataset.\n",
            "   ‚úÖ DermNet saved to: /kaggle/input/dermnet\n",
            "\n",
            "2Ô∏è‚É£  Downloading Mgmitesh Skin Disease Dataset...\n",
            "Using Colab cache for faster access to the 'skin-disease-detection-dataset' dataset.\n",
            "   ‚úÖ Mgmitesh saved to: /kaggle/input/skin-disease-detection-dataset\n",
            "\n",
            "3Ô∏è‚É£  Downloading Ismailpromus Skin Diseases Dataset...\n",
            "Using Colab cache for faster access to the 'skin-diseases-image-dataset' dataset.\n",
            "   ‚úÖ Ismailpromus saved to: /kaggle/input/skin-diseases-image-dataset\n",
            "\n",
            "================================================================================\n",
            "‚úÖ ALL DATASETS DOWNLOADED\n",
            "================================================================================\n",
            "\n",
            "üìÇ Processing DermNet dataset from: /kaggle/input/dermnet\n",
            "‚úÖ DermNet: 19,559 images\n",
            "\n",
            "üìÇ Processing Mgmitesh dataset from: /kaggle/input/skin-disease-detection-dataset\n",
            "‚úÖ Mgmitesh: 48,233 images\n",
            "\n",
            "üìÇ Processing Ismailpromus dataset from: /kaggle/input/skin-diseases-image-dataset\n",
            "‚úÖ Ismailpromus: 27,153 images\n",
            "\n",
            "‚úÖ Total images collected: 94,945\n",
            "‚úÖ Total unique labels: 48\n",
            "\n",
            "================================================================================\n",
            "STEP 2: STANDARDIZING DISEASE LABELS\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "STEP 3: FILTERING FOR CLINICAL DISEASES ONLY\n",
            "================================================================================\n",
            "‚úÖ Before filtering: 94,945 images\n",
            "‚úÖ After filtering: 41,914 images\n",
            "‚úÖ Removed: 53,031 images (cancer, benign, normal)\n",
            "‚úÖ Final unique diseases: 22\n",
            "\n",
            "================================================================================\n",
            "STEP 4: CREATING 80-20 STRATIFIED TRAIN-TEST SPLIT\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Training set: 33,531 images (80.0%)\n",
            "‚úÖ Test set: 8,383 images (20.0%)\n",
            "\n",
            "‚úÖ Saved: /content/drive/MyDrive/SkinDiseaseProject/train_dataset.csv\n",
            "‚úÖ Saved: /content/drive/MyDrive/SkinDiseaseProject/test_dataset.csv\n",
            "\n",
            "================================================================================\n",
            "FINAL DATASET STATISTICS\n",
            "================================================================================\n",
            "\n",
            "Category                                     Images        %\n",
            "============================================================\n",
            "FUNGAL INFECTIONS                            10,978   26.19%\n",
            "VIRAL INFECTIONS                              7,269   17.34%\n",
            "BACTERIAL INFECTIONS                            361    0.86%\n",
            "INFLAMMATORY/AUTOIMMUNE                      13,499   32.21%\n",
            "OTHER CONDITIONS                              7,568   18.06%\n",
            "============================================================\n",
            "TOTAL                                        41,914  100.00%\n",
            "\n",
            "================================================================================\n",
            "TOP 15 DISEASES BY IMAGE COUNT\n",
            "================================================================================\n",
            "\n",
            "Disease                                               Train     Test    Total\n",
            "================================================================================\n",
            "Acne and Rosacea                                      3,805      951    4,756\n",
            "Alopecia and Hair Loss                                  239       60      299\n",
            "Atopic Dermatitis                                     1,495      374    1,869\n",
            "Bacterial Skin Infections                               289       72      361\n",
            "Bullous Disease                                         449      112      561\n",
            "Chickenpox                                            2,641      660    3,301\n",
            "Contact Dermatitis                                      260       65      325\n",
            "Drug Eruptions                                          404      101      505\n",
            "Dyshidrotic Eczema                                    2,340      585    2,925\n",
            "Eczema                                                2,577      644    3,221\n",
            "Fungal Infections                                     5,245    1,311    6,556\n",
            "Herpes and STDs                                         406      101      507\n",
            "Lupus and Connective Tissue Disease                     420      105      525\n",
            "Nail Fungus                                           3,537      885    4,422\n",
            "Pigmentation Disorders                                  569      142      711\n",
            "\n",
            "================================================================================\n",
            "‚úÖ DATASET PREPARATION COMPLETE!\n",
            "================================================================================\n",
            "\n",
            "üìÅ Files ready for training:\n",
            "   1. /content/drive/MyDrive/SkinDiseaseProject/train_dataset.csv\n",
            "   2. /content/drive/MyDrive/SkinDiseaseProject/test_dataset.csv\n",
            "\n",
            "üí° Next step: Change runtime to T4 GPU and start training!\n",
            "\n",
            "‚úÖ Train and test CSVs are ready.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# COMPLETE DATASET SETUP - Downloads, Labels, CSVs\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "work_dir = '/content/drive/MyDrive/SkinDiseaseProject'\n",
        "os.makedirs(work_dir, exist_ok=True)\n",
        "os.chdir(work_dir)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"üì• DOWNLOADING ALL DATASETS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Delete old path files to force fresh download\n",
        "path_files = ['dermnet_path.txt', 'mgmitesh_path.txt', 'ismailpromus_path.txt']\n",
        "for file in path_files:\n",
        "    # Use absolute path\n",
        "    abs_file_path = os.path.join(work_dir, file)\n",
        "    if os.path.exists(abs_file_path):\n",
        "        os.remove(abs_file_path)\n",
        "        print(f\"üóëÔ∏è  Removed old {file}\")\n",
        "\n",
        "print(\"\\nüì• Downloading datasets (this may take 10-15 minutes)....\\n\")\n",
        "\n",
        "# Download Dataset 1: DermNet\n",
        "print(\"1Ô∏è‚É£  Downloading DermNet...\")\n",
        "dermnet_path = kagglehub.dataset_download('shubhamgoel27/dermnet')\n",
        "# Use absolute path\n",
        "with open(os.path.join(work_dir, 'dermnet_path.txt'), 'w') as f:\n",
        "    f.write(dermnet_path)\n",
        "print(f\"   ‚úÖ DermNet saved to: {dermnet_path}\")\n",
        "\n",
        "# Download Dataset 2: Mgmitesh\n",
        "print(\"\\n2Ô∏è‚É£  Downloading Mgmitesh Skin Disease Dataset...\")\n",
        "mgmitesh_path = kagglehub.dataset_download('mgmitesh/skin-disease-detection-dataset')\n",
        "# Use absolute path\n",
        "with open(os.path.join(work_dir, 'mgmitesh_path.txt'), 'w') as f:\n",
        "    f.write(mgmitesh_path)\n",
        "print(f\"   ‚úÖ Mgmitesh saved to: {mgmitesh_path}\")\n",
        "\n",
        "# Download Dataset 3: Ismailpromus\n",
        "print(\"\\n3Ô∏è‚É£  Downloading Ismailpromus Skin Diseases Dataset...\")\n",
        "ismailpromus_path = kagglehub.dataset_download('ismailpromus/skin-diseases-image-dataset')\n",
        "# Use absolute path\n",
        "with open(os.path.join(work_dir, 'ismailpromus_path.txt'), 'w') as f:\n",
        "    f.write(ismailpromus_path)\n",
        "print(f\"   ‚úÖ Ismailpromus saved to: {ismailpromus_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ ALL DATASETS DOWNLOADED\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ============================================================\n",
        "# LABEL ALL IMAGES AND CREATE TRAIN/TEST CSVs\n",
        "# ============================================================\n",
        "\n",
        "all_data = []\n",
        "\n",
        "# ============================================================================\n",
        "# Process DermNet Dataset\n",
        "# ============================================================================\n",
        "print(f\"\\nüìÇ Processing DermNet dataset from: {dermnet_path}\")\n",
        "for split in ['train', 'test']:\n",
        "    split_path = os.path.join(dermnet_path, split)\n",
        "    if os.path.exists(split_path):\n",
        "        disease_folders = os.listdir(split_path)\n",
        "        for disease in disease_folders:\n",
        "            disease_path = os.path.join(split_path, disease)\n",
        "            if os.path.isdir(disease_path):\n",
        "                images = [f for f in os.listdir(disease_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "                for img in images:\n",
        "                    img_path = os.path.join(disease_path, img)\n",
        "                    all_data.append({\n",
        "                        'image_path': img_path,\n",
        "                        'label': disease,\n",
        "                        'dataset_source': 'DermNet'\n",
        "                    })\n",
        "    else:\n",
        "         print(f\"‚ùå DermNet split path does not exist: {split_path}\")\n",
        "\n",
        "\n",
        "print(f\"‚úÖ DermNet: {len([d for d in all_data if d['dataset_source'] == 'DermNet']):,} images\")\n",
        "\n",
        "# ============================================================================\n",
        "# Process Mgmitesh Dataset\n",
        "# ============================================================================\n",
        "print(f\"\\nüìÇ Processing Mgmitesh dataset from: {mgmitesh_path}\")\n",
        "mgmitesh_start = len(all_data)\n",
        "for split in ['train', 'val']:\n",
        "    split_path = os.path.join(mgmitesh_path, split)\n",
        "    if os.path.exists(split_path):\n",
        "        disease_folders = os.listdir(split_path)\n",
        "        for disease in disease_folders:\n",
        "            disease_path = os.path.join(split_path, disease)\n",
        "            if os.path.isdir(disease_path):\n",
        "                images = [f for f in os.listdir(disease_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "                for img in images:\n",
        "                    img_path = os.path.join(disease_path, img)\n",
        "                    all_data.append({\n",
        "                        'image_path': img_path,\n",
        "                        'label': disease,\n",
        "                        'dataset_source': 'Mgmitesh'\n",
        "                    })\n",
        "    else:\n",
        "         print(f\"‚ùå Mgmitesh split path does not exist: {split_path}\")\n",
        "\n",
        "print(f\"‚úÖ Mgmitesh: {len(all_data) - mgmitesh_start:,} images\")\n",
        "\n",
        "# ============================================================================\n",
        "# Process Ismailpromus Dataset\n",
        "# ============================================================================\n",
        "print(f\"\\nüìÇ Processing Ismailpromus dataset from: {ismailpromus_path}\")\n",
        "ismailpromus_start = len(all_data)\n",
        "img_classes_path = os.path.join(ismailpromus_path, 'IMG_CLASSES')\n",
        "if os.path.exists(img_classes_path):\n",
        "    disease_folders = os.listdir(img_classes_path)\n",
        "    for disease in disease_folders:\n",
        "        disease_path = os.path.join(img_classes_path, disease)\n",
        "        if os.path.isdir(disease_path):\n",
        "            images = [f for f in os.listdir(disease_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "            for img in images:\n",
        "                img_path = os.path.join(disease_path, img)\n",
        "                all_data.append({\n",
        "                    'image_path': img_path,\n",
        "                    'label': disease,\n",
        "                    'dataset_source': 'Ismailpromus'\n",
        "                })\n",
        "else:\n",
        "    print(f\"‚ùå Ismailpromus IMG_CLASSES path does not exist: {img_classes_path}\")\n",
        "\n",
        "\n",
        "print(f\"‚úÖ Ismailpromus: {len(all_data) - ismailpromus_start:,} images\")\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(all_data)\n",
        "\n",
        "print(f\"\\n‚úÖ Total images collected: {len(df):,}\")\n",
        "print(f\"‚úÖ Total unique labels: {df['label'].nunique() if 'label' in df.columns else 0}\")\n",
        "\n",
        "# Check if DataFrame is empty\n",
        "if df.empty:\n",
        "    print(\"\\n‚ùå No images found in any dataset paths. Please check paths and contents.\")\n",
        "else:\n",
        "    # ============================================================================\n",
        "    # STEP 2: Standardize Labels\n",
        "    # ============================================================================\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"STEP 2: STANDARDIZING DISEASE LABELS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    label_mapping = {\n",
        "        # Fungal infections\n",
        "        'Tinea Ringworm Candidiasis and other Fungal Infections': 'Fungal Infections',\n",
        "        'Ringworm': 'Fungal Infections',\n",
        "        'ringworm': 'Fungal Infections',\n",
        "        '9. Tinea Ringworm Candidiasis and other Fungal Infections - 1.7k': 'Fungal Infections',\n",
        "        'Nail Fungus and other Nail Disease': 'Nail Fungus',\n",
        "        'Nail Fungus': 'Nail Fungus',\n",
        "\n",
        "        # Viral infections\n",
        "        'Warts Molluscum and other Viral Infections': 'Viral Skin Infections',\n",
        "        '10. Warts Molluscum and other Viral Infections - 2103': 'Viral Skin Infections',\n",
        "        'Warts': 'Viral Skin Infections',\n",
        "        'Chickenpox': 'Chickenpox',\n",
        "        'chickenpox': 'Chickenpox',\n",
        "        'Herpes HPV and other STDs Photos': 'Herpes and STDs',\n",
        "\n",
        "        # Bacterial infections\n",
        "        'Cellulitis Impetigo and other Bacterial Infections': 'Bacterial Skin Infections',\n",
        "        'Cellulitis': 'Bacterial Skin Infections',\n",
        "\n",
        "        # Inflammatory conditions\n",
        "        '1. Eczema 1677': 'Eczema',\n",
        "        'Eczema Photos': 'Eczema',\n",
        "        'Eczema': 'Eczema',\n",
        "        'Dyshidrotic Eczema': 'Dyshidrotic Eczema',\n",
        "        '3. Atopic Dermatitis - 1.25k': 'Atopic Dermatitis',\n",
        "        'Atopic Dermatitis Photos': 'Atopic Dermatitis',\n",
        "        'Atopic Dermatitis': 'Atopic Dermatitis',\n",
        "        '7. Psoriasis pictures Lichen Planus and related diseases - 2k': 'Psoriasis and Lichen Planus',\n",
        "        'Psoriasis pictures Lichen Planus and related diseases': 'Psoriasis and Lichen Planus',\n",
        "        'Psoriasis': 'Psoriasis and Lichen Planus',\n",
        "        'Bullous Disease Photos': 'Bullous Disease',\n",
        "        'Lupus and other Connective Tissue diseases': 'Lupus and Connective Tissue Disease',\n",
        "        'Vasculitis Photos': 'Vasculitis',\n",
        "        'Poison Ivy Photos and other Contact Dermatitis': 'Contact Dermatitis',\n",
        "        'Urticaria Hives': 'Urticaria',\n",
        "\n",
        "        # Other conditions\n",
        "        'Acne and Rosacea Photos': 'Acne and Rosacea',\n",
        "        'Acne': 'Acne and Rosacea',\n",
        "        'acne': 'Acne and Rosacea',\n",
        "        'Light Diseases and Disorders of Pigmentation': 'Pigmentation Disorders',\n",
        "        'Scabies Lyme Disease and other Infestations and Bites': 'Scabies and Infestations',\n",
        "        'Exanthems and Drug Eruptions': 'Drug Eruptions',\n",
        "        'Hair Loss Photos Alopecia and other Hair Diseases': 'Alopecia and Hair Loss',\n",
        "        'Systemic Disease': 'Systemic Disease',\n",
        "    }\n",
        "\n",
        "    df['label_standardized'] = df['label'].map(label_mapping).fillna(df['label'])\n",
        "\n",
        "    # ============================================================================\n",
        "    # STEP 3: Filter Out Non-Clinical Diseases\n",
        "    # ============================================================================\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"STEP 3: FILTERING FOR CLINICAL DISEASES ONLY\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Exclude cancer, benign tumors, and normal skin\n",
        "    exclude_diseases = [\n",
        "        '5. Melanocytic Nevi (NV) - 7970',\n",
        "        '4. Basal Cell Carcinoma (BCC) 3323',\n",
        "        '2. Melanoma 15.75k',\n",
        "        'Melanoma',\n",
        "        'Basal Cell Carcinoma',\n",
        "        'Actinic Keratosis',\n",
        "        'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions',\n",
        "        'Squamous Cell Carcinoma',\n",
        "        'Melanoma Skin Cancer Nevi and Moles',\n",
        "        'Nevus',\n",
        "        '6. Benign Keratosis-like Lesions (BKL) 2624',\n",
        "        '8. Seborrheic Keratoses and other Benign Tumors - 1.8k',\n",
        "        'Seborrheic Keratoses',\n",
        "        'Seborrheic Keratosis',\n",
        "        'Pigmented Benign Keratosis',\n",
        "        'Dermato Fibroma',\n",
        "        'Vascular Lesion',\n",
        "        'Vascular Tumors',\n",
        "        'Normal Skin',\n",
        "    ]\n",
        "\n",
        "    df_filtered = df[~df['label_standardized'].isin(exclude_diseases)].copy()\n",
        "\n",
        "    print(f\"‚úÖ Before filtering: {len(df):,} images\")\n",
        "    print(f\"‚úÖ After filtering: {len(df_filtered):,} images\")\n",
        "    print(f\"‚úÖ Removed: {len(df) - len(df_filtered):,} images (cancer, benign, normal)\")\n",
        "    print(f\"‚úÖ Final unique diseases: {df_filtered['label_standardized'].nunique()}\")\n",
        "\n",
        "    # ============================================================================\n",
        "    # STEP 4: Create 80-20 Stratified Train-Test Split\n",
        "    # ============================================================================\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"STEP 4: CREATING 80-20 STRATIFIED TRAIN-TEST SPLIT\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Perform stratified split\n",
        "    if df_filtered.empty or df_filtered['label_standardized'].nunique() < 2:\n",
        "        print(\"\\n‚ùå Not enough data or unique classes for stratified split after filtering.\")\n",
        "    else:\n",
        "        train_df, test_df = train_test_split(\n",
        "            df_filtered,\n",
        "            test_size=0.2,\n",
        "            stratify=df_filtered['label_standardized'],\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        # Rename column for final CSV\n",
        "        train_df = train_df[['image_path', 'label_standardized', 'dataset_source']].copy()\n",
        "        test_df = test_df[['image_path', 'label_standardized', 'dataset_source']].copy()\n",
        "        train_df = train_df.rename(columns={'label_standardized': 'label'})\n",
        "        test_df = test_df.rename(columns={'label_standardized': 'label'})\n",
        "\n",
        "        print(f\"\\n‚úÖ Training set: {len(train_df):,} images ({len(train_df)/len(df_filtered)*100:.1f}%)\")\n",
        "        print(f\"‚úÖ Test set: {len(test_df):,} images ({len(test_df)/len(df_filtered)*100:.1f}%)\")\n",
        "\n",
        "        # Save CSVs\n",
        "        train_csv_path = '/content/drive/MyDrive/SkinDiseaseProject/train_dataset.csv'\n",
        "        test_csv_path = '/content/drive/MyDrive/SkinDiseaseProject/test_dataset.csv'\n",
        "\n",
        "        train_df.to_csv(train_csv_path, index=False)\n",
        "        test_df.to_csv(test_csv_path, index=False)\n",
        "\n",
        "        print(f\"\\n‚úÖ Saved: {train_csv_path}\")\n",
        "        print(f\"‚úÖ Saved: {test_csv_path}\")\n",
        "\n",
        "        # ============================================================================\n",
        "        # STEP 5: Display Statistics\n",
        "        # ============================================================================\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"FINAL DATASET STATISTICS\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Count by category\n",
        "        # Check if train_df and test_df have 'label' column before combining value counts\n",
        "        if 'label' in train_df.columns and 'label' in test_df.columns:\n",
        "            disease_counts = train_df['label'].value_counts().add(test_df['label'].value_counts(), fill_value=0)\n",
        "\n",
        "            fungal_diseases = ['Fungal Infections', 'Nail Fungus']\n",
        "            viral_diseases = ['Chickenpox', 'Viral Skin Infections', 'Herpes and STDs']\n",
        "            bacterial_diseases = ['Bacterial Skin Infections']\n",
        "            inflammatory_diseases = ['Eczema', 'Dyshidrotic Eczema', 'Atopic Dermatitis',\n",
        "                                    'Psoriasis and Lichen Planus', 'Bullous Disease',\n",
        "                                    'Lupus and other Connective Tissue Disease', 'Vasculitis',\n",
        "                                    'Contact Dermatitis', 'Urticaria']\n",
        "            other_diseases = ['Acne and Rosacea', 'Systemic Disease', 'Pigmentation Disorders',\n",
        "                            'Scabies and Infestations', 'Drug Eruptions', 'Alopecia and Hair Loss']\n",
        "\n",
        "            def count_category(disease_list):\n",
        "                return sum(disease_counts.get(d, 0) for d in disease_list)\n",
        "\n",
        "            print(f\"\\n{'Category':<40} {'Images':>10} {'%':>8}\")\n",
        "            print(\"=\"*60)\n",
        "            print(f\"{'FUNGAL INFECTIONS':<40} {count_category(fungal_diseases):>10,} {count_category(fungal_diseases)/len(df_filtered)*100:>7.2f}%\")\n",
        "            print(f\"{'VIRAL INFECTIONS':<40} {count_category(viral_diseases):>10,} {count_category(viral_diseases)/len(df_filtered)*100:>7.2f}%\")\n",
        "            print(f\"{'BACTERIAL INFECTIONS':<40} {count_category(bacterial_diseases):>10,} {count_category(bacterial_diseases)/len(df_filtered)*100:>7.2f}%\")\n",
        "            print(f\"{'INFLAMMATORY/AUTOIMMUNE':<40} {count_category(inflammatory_diseases):>10,} {count_category(inflammatory_diseases)/len(df_filtered)*100:>7.2f}%\")\n",
        "            print(f\"{'OTHER CONDITIONS':<40} {count_category(other_diseases):>10,} {count_category(other_diseases)/len(df_filtered)*100:>7.2f}%\")\n",
        "            print(\"=\"*60)\n",
        "            print(f\"{'TOTAL':<40} {len(df_filtered):>10,} {100.0:>7.2f}%\")\n",
        "\n",
        "            # Display top diseases\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"TOP 15 DISEASES BY IMAGE COUNT\")\n",
        "            print(\"=\"*80)\n",
        "            print(f\"\\n{'Disease':<50} {'Train':>8} {'Test':>8} {'Total':>8}\")\n",
        "            print(\"=\"*80)\n",
        "\n",
        "            for disease in disease_counts.head(15).index:\n",
        "                train_count = (train_df['label'] == disease).sum()\n",
        "                test_count = (test_df['label'] == disease).sum()\n",
        "                total = train_count + test_count\n",
        "                print(f\"{disease:<50} {train_count:>8,} {test_count:>8,} {total:>8,}\")\n",
        "\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"‚úÖ DATASET PREPARATION COMPLETE!\")\n",
        "            print(\"=\"*80)\n",
        "            print(\"\\nüìÅ Files ready for training:\")\n",
        "            print(f\"   1. {train_csv_path}\")\n",
        "            print(f\"   2. {test_csv_path}\")\n",
        "            print(\"\\nüí° Next step: Change runtime to T4 GPU and start training!\")\n",
        "        else:\n",
        "             print(\"\\n‚ùå Train/Test DataFrames are empty. Cannot display statistics.\")\n",
        "\n",
        "    # Ensure train_csv_path and test_csv_path are defined even if an error occurs\n",
        "    if 'train_csv_path' not in locals():\n",
        "        train_csv_path = '/content/drive/MyDrive/SkinDiseaseProject/train_dataset.csv'\n",
        "    if 'test_csv_path' not in locals():\n",
        "        test_csv_path = '/content/drive/MyDrive/SkinDiseaseProject/test_dataset.csv'\n",
        "\n",
        "    # Add a message indicating if CSVs were saved\n",
        "    if os.path.exists(train_csv_path) and os.path.exists(test_csv_path):\n",
        "        print(\"\\n‚úÖ Train and test CSVs are ready.\")\n",
        "    else:\n",
        "        print(\"\\n‚ùå Train and test CSVs were NOT successfully created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0431ecd2"
      },
      "source": [
        "Let's inspect the downloaded dataset paths to understand where the files are located and why they are not being processed correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef8594d2",
        "outputId": "0389a1d6-a245-418a-f26c-38761464ab2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DermNet path: /kaggle/input/dermnet\n",
            "Mgmitesh path: /kaggle/input/skin-disease-detection-dataset\n",
            "Ismailpromus path: /kaggle/input/skin-diseases-image-dataset\n",
            "\n",
            "Inspecting contents:\n",
            "\n",
            "Contents of /kaggle/input/dermnet (first 10 items):\n",
            "- test\n",
            "- train\n",
            "\n",
            "Contents of /kaggle/input/skin-disease-detection-dataset (first 10 items):\n",
            "- val\n",
            "- train\n",
            "\n",
            "Contents of /kaggle/input/skin-diseases-image-dataset (first 10 items):\n",
            "- IMG_CLASSES\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Read dataset paths from the files created in the first cell\n",
        "try:\n",
        "    with open('dermnet_path.txt', 'r') as f:\n",
        "        dermnet_path = f.read().strip()\n",
        "    with open('mgmitesh_path.txt', 'r') as f:\n",
        "        mgmitesh_path = f.read().strip()\n",
        "    with open('ismailpromus_path.txt', 'r') as f:\n",
        "        ismailpromus_path = f.read().strip()\n",
        "\n",
        "    print(f\"DermNet path: {dermnet_path}\")\n",
        "    print(f\"Mgmitesh path: {mgmitesh_path}\")\n",
        "    print(f\"Ismailpromus path: {ismailpromus_path}\")\n",
        "\n",
        "    print(\"\\nInspecting contents:\")\n",
        "\n",
        "    # Function to list contents with a limit\n",
        "    def list_dir_limited(path, limit=10):\n",
        "        if os.path.exists(path):\n",
        "            print(f\"\\nContents of {path} (first {limit} items):\")\n",
        "            try:\n",
        "                items = os.listdir(path)\n",
        "                for i, item in enumerate(items[:limit]):\n",
        "                    print(f\"- {item}\")\n",
        "                if len(items) > limit:\n",
        "                    print(f\"... and {len(items) - limit} more items\")\n",
        "            except Exception as e:\n",
        "                print(f\"Could not list contents: {e}\")\n",
        "        else:\n",
        "            print(f\"\\nPath does not exist: {path}\")\n",
        "\n",
        "    list_dir_limited(dermnet_path)\n",
        "    list_dir_limited(mgmitesh_path)\n",
        "    list_dir_limited(ismailpromus_path)\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Dataset path files not found. Please run the first cell to download datasets and create path files.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9zULbGDY90y",
        "outputId": "31f3c4aa-e503-45f3-94b7-c277485a9b0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU: Tesla T4\n",
            "GPU Memory: 14.7 GB\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.autograd import Function\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import ImageFolder\n",
        "from PIL import Image\n",
        "from torch.utils.data import Subset\n",
        "from timm.layers import DropPath, trunc_normal_, Mlp\n",
        "from timm.utils import accuracy\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUNORuu7ZLzu",
        "outputId": "29d6f4ea-ca9a-47dc-e26e-e92c00175ff5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Image preprocessing module loaded (FIXED)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Image Preprocessing Module - FIXED FOR SIZE CONSISTENCY\n",
        "# ============================================================\n",
        "\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "\n",
        "class SimpleMedicalImagePreprocessor:\n",
        "    \"\"\"Minimal preprocessing for dermatology images - FIXED\"\"\"\n",
        "    def __init__(self, img_size=224):\n",
        "        self.img_size = img_size\n",
        "        self.normalize_stats = {\n",
        "            'mean': [0.485, 0.456, 0.406],\n",
        "            'std': [0.229, 0.224, 0.225]\n",
        "        }\n",
        "\n",
        "    def get_train_transforms(self):\n",
        "        \"\"\"Training transforms with data augmentation\"\"\"\n",
        "        return T.Compose([\n",
        "            T.Resize((self.img_size, self.img_size)),  # ‚úÖ FIXED - force exact size\n",
        "            T.RandomHorizontalFlip(p=0.5),\n",
        "            T.RandomRotation(20),\n",
        "            T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(\n",
        "                mean=self.normalize_stats['mean'],\n",
        "                std=self.normalize_stats['std']\n",
        "            ),\n",
        "        ])\n",
        "\n",
        "    def get_val_transforms(self):\n",
        "        \"\"\"Validation transforms - no augmentation\"\"\"\n",
        "        return T.Compose([\n",
        "            T.Resize((self.img_size, self.img_size)),  # ‚úÖ FIXED - force exact size\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(\n",
        "                mean=self.normalize_stats['mean'],\n",
        "                std=self.normalize_stats['std']\n",
        "            ),\n",
        "        ])\n",
        "\n",
        "print(\"‚úÖ Image preprocessing module loaded (FIXED)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSL367ihZXNs",
        "outputId": "a2772f1d-a66c-4697-ad21-9559414e2309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Custom dataset class loaded (FIXED)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Custom Dataset Class - FIXED FOR SIZE CONSISTENCY\n",
        "# ============================================================\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    \"\"\"Enhanced dataset with size validation - FIXED\"\"\"\n",
        "    def __init__(self, csv_file, transform=None, img_size=224, validate=False):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "        self.img_size = img_size\n",
        "\n",
        "        # Build label map\n",
        "        unique_labels = sorted(self.df['label'].unique())\n",
        "        self.label2idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "        self.idx2label = {idx: label for label, idx in self.label2idx.items()}\n",
        "\n",
        "        # Optional validation\n",
        "        if validate:\n",
        "            self._validate_images()\n",
        "\n",
        "    def _validate_images(self):\n",
        "        \"\"\"Check if image files exist\"\"\"\n",
        "        print(f\"üîç Validating image paths and integrity for {len(self.df)} samples...\")\n",
        "        invalid_rows = []\n",
        "        for idx, row in self.df.iterrows():\n",
        "            if not os.path.exists(row['image_path']):\n",
        "                invalid_rows.append(idx)\n",
        "\n",
        "        if invalid_rows:\n",
        "            print(f\"‚ö†Ô∏è Warning: {len(invalid_rows)} invalid image paths found\")\n",
        "            self.df = self.df.drop(invalid_rows).reset_index(drop=True)\n",
        "\n",
        "        print(f\"‚úÖ Validation complete. {len(self.df)} valid images remaining.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.df.iloc[idx]['image_path']\n",
        "        label = self.df.iloc[idx]['label']\n",
        "\n",
        "        try:\n",
        "            # Load image\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "            # ‚úÖ CRITICAL FIX: Force resize BEFORE transform\n",
        "            if image.size != (self.img_size, self.img_size):\n",
        "                image = image.resize((self.img_size, self.img_size), Image.BILINEAR)\n",
        "\n",
        "            # Apply transforms\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "\n",
        "            # Convert label to index\n",
        "            label_idx = self.label2idx[label]\n",
        "            label_tensor = torch.tensor(label_idx, dtype=torch.long)\n",
        "\n",
        "            return image, label_tensor\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading image {img_path}: {e}\")\n",
        "            # Return blank image on error\n",
        "            blank = torch.zeros(3, self.img_size, self.img_size)\n",
        "            return blank, torch.tensor(0, dtype=torch.long)\n",
        "\n",
        "print(\"‚úÖ Custom dataset class loaded (FIXED)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hez2Qz25Za60",
        "outputId": "236c6307-c971-4aca-9b5f-cde1948905de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Medical components loaded (LaplaceConv2d, MedicalGhostHead)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Cell 4: Enhanced Medical Components\n",
        "# ============================================================\n",
        "\n",
        "class LaplaceConv2d(nn.Module):\n",
        "    \"\"\"Laplacian edge detection for boundary analysis\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, 3, padding=1, bias=False)\n",
        "        # Initialize with Laplacian kernel\n",
        "        laplacian_kernel = torch.tensor([[[[-1, -1, -1],\n",
        "                                           [-1,  8, -1],\n",
        "                                           [-1, -1, -1]]]], dtype=torch.float32)\n",
        "        self.conv.weight.data = laplacian_kernel.repeat(out_channels, in_channels, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class MedicalGhostHead(nn.Module):\n",
        "    \"\"\"Enhanced Ghost Head for Medical Imaging\"\"\"\n",
        "    def __init__(self, channels, kernel_size, num_heads=6, medical_patterns=True):\n",
        "        super().__init__()\n",
        "        self.medical_patterns = medical_patterns\n",
        "        self.channels = channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.num_heads = num_heads\n",
        "        self.k_elems = kernel_size ** 2\n",
        "\n",
        "        # Ghost params shaped to align with h_attn\n",
        "        self.ghost_mul = nn.Parameter(torch.randn(1, num_heads, self.k_elems, 1))\n",
        "        self.ghost_add = nn.Parameter(torch.zeros(1, num_heads, self.k_elems, 1))\n",
        "        trunc_normal_(self.ghost_add, std=0.02)\n",
        "\n",
        "        if medical_patterns:\n",
        "            # Partition heads into groups (texture / boundary / color)\n",
        "            h_per_group = max(1, num_heads // 3)\n",
        "            groups = []\n",
        "            start = 0\n",
        "            while start < num_heads:\n",
        "                end = min(start + h_per_group, num_heads)\n",
        "                groups.append((start, end))\n",
        "                start = end\n",
        "            self.pattern_groups = groups\n",
        "\n",
        "            # Create per-group modulation tensors\n",
        "            self.group_modulations = nn.ParameterList()\n",
        "            for (s, e) in groups:\n",
        "                g_size = e - s\n",
        "                self.group_modulations.append(\n",
        "                    nn.Parameter(torch.randn(1, g_size, self.k_elems, 1))\n",
        "                )\n",
        "\n",
        "            self.medical_fusion = nn.Conv2d(channels, channels, 1)\n",
        "\n",
        "    def forward(self, h_attn, lam=1.0, gamma=1.0):\n",
        "        \"\"\"\n",
        "        h_attn: (B, num_heads, k_elems, HW)\n",
        "        returns: same shape\n",
        "        \"\"\"\n",
        "        B, Hn, K2, HW = h_attn.shape\n",
        "        assert Hn == self.num_heads and K2 == self.k_elems\n",
        "\n",
        "        # Apply scaling\n",
        "        ghost_mul = self.ghost_mul ** lam if lam != 0 else None\n",
        "        ghost_add = self.ghost_add * gamma if gamma != 0 else None\n",
        "\n",
        "        # Broadcasted computation\n",
        "        if ghost_mul is not None and ghost_add is not None:\n",
        "            enhanced_attn = ghost_mul * h_attn + ghost_add\n",
        "        elif ghost_mul is not None:\n",
        "            enhanced_attn = ghost_mul * h_attn\n",
        "        elif ghost_add is not None:\n",
        "            enhanced_attn = h_attn + ghost_add\n",
        "        else:\n",
        "            enhanced_attn = h_attn\n",
        "\n",
        "        # Medical pattern enhancement\n",
        "        if self.medical_patterns and len(self.pattern_groups) > 0:\n",
        "            modulated = []\n",
        "            for idx, (s, e) in enumerate(self.pattern_groups):\n",
        "                h_part = enhanced_attn[:, s:e, :, :]\n",
        "                mod = self.group_modulations[idx]\n",
        "                h_mod = h_part * mod\n",
        "                modulated.append(h_mod)\n",
        "\n",
        "            medical_enhanced = torch.cat(modulated, dim=1)\n",
        "            combined = enhanced_attn + 0.3 * medical_enhanced\n",
        "            return combined\n",
        "\n",
        "        return enhanced_attn\n",
        "\n",
        "print(\"‚úÖ Medical components loaded (LaplaceConv2d, MedicalGhostHead)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTCv8TMYZeeY",
        "outputId": "1a524d07-eb2a-4d15-f1f6-1fb6b8d906fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ PathoScaleSA module loaded (COMPLETELY FIXED)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Cell 5: PathoScaleSA (COMPLETELY FIXED)\n",
        "# ============================================================\n",
        "\n",
        "class PathoScaleSA(nn.Module):\n",
        "    \"\"\"Pathology-guided Multi-Scale Self-Attention for Medical Imaging\"\"\"\n",
        "    def __init__(self, dim, num_heads=6, kernel_sizes=[3, 5, 7], medical_prior=True,\n",
        "                 cross_scale_fusion=True, pathology_guided=True, qkv_bias=False,\n",
        "                 attn_drop=0., proj_drop=0., lam=1.0, gamma=1.0):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        self.kernel_sizes = kernel_sizes\n",
        "        self.medical_prior = medical_prior\n",
        "        self.cross_scale_fusion = cross_scale_fusion\n",
        "        self.pathology_guided = pathology_guided\n",
        "        self.lam = lam\n",
        "        self.gamma = gamma\n",
        "        self.scale = (dim // num_heads) ** -0.5\n",
        "\n",
        "        # Multi-scale ELSA modules\n",
        "        self.multi_scale_attn = nn.ModuleList()\n",
        "        for ks in kernel_sizes:\n",
        "            self.multi_scale_attn.append(nn.ModuleDict({\n",
        "                'qkv': nn.Conv2d(dim, dim * 3, 1, bias=qkv_bias),\n",
        "                'attn_gen': nn.Sequential(\n",
        "                    nn.Conv2d(dim, dim, ks, padding=ks//2, groups=num_heads),\n",
        "                    nn.GELU(),\n",
        "                    nn.Conv2d(dim, ks**2 * num_heads, 1)\n",
        "                ),\n",
        "                'ghost_head': MedicalGhostHead(dim, ks, num_heads, medical_patterns=True)\n",
        "            }))\n",
        "\n",
        "        # Medical prior attention\n",
        "        if medical_prior:\n",
        "            self.medical_gate = nn.Sequential(\n",
        "                nn.AdaptiveAvgPool2d(1),\n",
        "                nn.Flatten(),\n",
        "                nn.Linear(dim, dim//4),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(dim//4, len(kernel_sizes)),\n",
        "                nn.Sigmoid()\n",
        "            )\n",
        "\n",
        "        # Cross-scale fusion\n",
        "        if cross_scale_fusion:\n",
        "            self.fusion_conv = nn.Conv2d(dim * len(kernel_sizes), dim, 1)\n",
        "            self.fusion_norm = nn.LayerNorm(dim)\n",
        "\n",
        "        # Pathology-guided attention branches - FIXED\n",
        "        if pathology_guided:\n",
        "            self.texture_branch = nn.Conv2d(dim, dim//2, 3, padding=1)\n",
        "            self.color_branch = nn.Conv2d(dim, dim//2, 1)\n",
        "            self.boundary_branch = LaplaceConv2d(dim, dim//2)\n",
        "            # Total pathology features: 3 * (dim//2) = dim * 1.5\n",
        "            # Combined with fused: dim + dim*1.5 = dim * 2.5\n",
        "            pathology_dim = 3 * (dim // 2)  # Total from 3 branches\n",
        "            self.pathology_fusion = nn.Conv2d(dim + pathology_dim, dim, 1)\n",
        "\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, H, W, C = x.shape\n",
        "        x_2d = x.permute(0, 3, 1, 2)  # B, C, H, W\n",
        "\n",
        "        scale_outputs = []\n",
        "\n",
        "        # Process each scale\n",
        "        for i, (ks, scale_module) in enumerate(zip(self.kernel_sizes, self.multi_scale_attn)):\n",
        "            qkv = scale_module['qkv'](x_2d)\n",
        "            q, k, v = torch.chunk(qkv, 3, dim=1)\n",
        "\n",
        "            # Hadamard product for attention generation\n",
        "            hadamard_product = q * k * self.scale\n",
        "            h_attn = scale_module['attn_gen'](hadamard_product)\n",
        "\n",
        "            # Reshape attention\n",
        "            h_attn = h_attn.reshape(B, self.num_heads, ks**2, H * W)\n",
        "            h_attn = h_attn.reshape(B * self.num_heads, ks**2, H * W)\n",
        "            h_attn = h_attn.softmax(dim=1)\n",
        "            h_attn = self.attn_drop(h_attn)\n",
        "\n",
        "            # Apply ghost head enhancement\n",
        "            h_attn_reshaped = h_attn.reshape(B, self.num_heads, ks**2, H * W)\n",
        "            enhanced_attn = scale_module['ghost_head'](h_attn_reshaped, self.lam, self.gamma)\n",
        "            enhanced_attn = enhanced_attn.reshape(B * self.num_heads, ks**2, H * W)\n",
        "\n",
        "            # Apply attention to values using unfold\n",
        "            v_unfolded = F.unfold(v, kernel_size=ks, padding=ks//2, stride=1)\n",
        "            v_unfolded = v_unfolded.reshape(B, C, ks**2, H * W)\n",
        "            v_unfolded = v_unfolded.reshape(B * self.num_heads, C // self.num_heads, ks**2, H * W)\n",
        "\n",
        "            # Weighted sum\n",
        "            attended_v = torch.einsum('bchw,bhw->bcw', v_unfolded, enhanced_attn)\n",
        "            attended_v = attended_v.reshape(B, C, H, W)\n",
        "\n",
        "            scale_outputs.append(attended_v)\n",
        "\n",
        "        # Medical prior weighting\n",
        "        if self.medical_prior:\n",
        "            scale_weights = self.medical_gate(x_2d)  # (B, num_scales)\n",
        "            scale_weights = scale_weights.unsqueeze(-1).unsqueeze(-1)  # (B, num_scales, 1, 1)\n",
        "            scale_outputs = [out * scale_weights[:, i:i+1, :, :]\n",
        "                           for i, out in enumerate(scale_outputs)]\n",
        "\n",
        "        # Cross-scale fusion\n",
        "        if self.cross_scale_fusion:\n",
        "            fused = torch.cat(scale_outputs, dim=1)\n",
        "            fused = self.fusion_conv(fused)\n",
        "        else:\n",
        "            fused = sum(scale_outputs) / len(scale_outputs)\n",
        "\n",
        "        # Pathology-guided enhancement\n",
        "        if self.pathology_guided:\n",
        "            texture_feat = self.texture_branch(fused)  # dim//2\n",
        "            color_feat = self.color_branch(fused)      # dim//2\n",
        "            boundary_feat = self.boundary_branch(fused) # dim//2\n",
        "\n",
        "            # Concatenate all pathology features (total: 3 * dim//2)\n",
        "            pathology_feat = torch.cat([texture_feat, color_feat, boundary_feat], dim=1)\n",
        "            # Concatenate with fused (total: dim + 3*dim//2)\n",
        "            combined_feat = torch.cat([fused, pathology_feat], dim=1)\n",
        "            fused = self.pathology_fusion(combined_feat)\n",
        "\n",
        "        # Back to token format\n",
        "        output = fused.permute(0, 2, 3, 1)  # B, H, W, C\n",
        "        output = self.proj(output)\n",
        "        output = self.proj_drop(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "class PathoScaleSABlock(nn.Module):\n",
        "    \"\"\"Complete PathoScaleSA Block with MLP\"\"\"\n",
        "    def __init__(self, dim, num_heads=6, kernel_sizes=[3, 5, 7], mlp_ratio=3.,\n",
        "                 drop=0., attn_drop=0., drop_path=0., act_layer=nn.GELU,\n",
        "                 norm_layer=nn.LayerNorm, medical_prior=True, cross_scale_fusion=True,\n",
        "                 pathology_guided=True, lam=1.0, gamma=1.0):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.norm1 = norm_layer(dim)\n",
        "\n",
        "        self.attn = PathoScaleSA(\n",
        "            dim=dim, num_heads=num_heads, kernel_sizes=kernel_sizes,\n",
        "            medical_prior=medical_prior, cross_scale_fusion=cross_scale_fusion,\n",
        "            pathology_guided=pathology_guided, attn_drop=attn_drop,\n",
        "            proj_drop=drop, lam=lam, gamma=gamma\n",
        "        )\n",
        "\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
        "        self.norm2 = norm_layer(dim)\n",
        "\n",
        "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
        "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim,\n",
        "                      act_layer=act_layer, drop=drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path(self.attn(self.norm1(x)))\n",
        "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
        "        return x\n",
        "\n",
        "print(\"‚úÖ PathoScaleSA module loaded (COMPLETELY FIXED)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrxqqQMPZi0k",
        "outputId": "20cd94b4-edb8-472a-cb33-f4b11d51b47e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Standard ELSA implementation loaded\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Cell 6: Standard ELSA Implementation\n",
        "# ============================================================\n",
        "\n",
        "class ELSAFunctionCUDA(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, features, ghost_mul, ghost_add, h_attn,\n",
        "                kernel_size=5, dilation=1, stride=1, version=''):\n",
        "        B, C, H, W = features.shape\n",
        "        _pad = kernel_size // 2 * dilation\n",
        "        features_unfolded = F.unfold(\n",
        "            features, kernel_size=kernel_size, dilation=dilation, padding=_pad, stride=stride) \\\n",
        "            .reshape(B, C, kernel_size ** 2, H * W)\n",
        "\n",
        "        if ghost_mul is not None:\n",
        "            ghost_mul = ghost_mul.reshape(B, C, kernel_size ** 2, 1)\n",
        "        if ghost_add is not None:\n",
        "            ghost_add = ghost_add.reshape(B, C, kernel_size ** 2, 1)\n",
        "\n",
        "        h_attn = h_attn.reshape(B, 1, kernel_size ** 2, H * W)\n",
        "\n",
        "        # Compute filters\n",
        "        if ghost_mul is not None and ghost_add is not None:\n",
        "            filters = ghost_mul * h_attn + ghost_add\n",
        "        elif ghost_mul is not None:\n",
        "            filters = ghost_mul * h_attn\n",
        "        elif ghost_add is not None:\n",
        "            filters = h_attn + ghost_add\n",
        "        else:\n",
        "            filters = h_attn\n",
        "\n",
        "        return (features_unfolded * filters).sum(2).reshape(B, C, H, W)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return grad_output, None, None, None, None, None, None, None\n",
        "\n",
        "def elsa_op(features, ghost_mul, ghost_add, h_attn, lam, gamma,\n",
        "            kernel_size=5, dilation=1, stride=1, version=''):\n",
        "    _B, _C = features.shape[:2]\n",
        "\n",
        "    if ghost_mul is not None:\n",
        "        ghost_mul = ghost_mul ** lam if lam != 0 else None\n",
        "    if ghost_add is not None:\n",
        "        ghost_add = ghost_add * gamma if gamma != 0 else None\n",
        "\n",
        "    B, C, H, W = features.shape\n",
        "    _pad = kernel_size // 2 * dilation\n",
        "    features_unfolded = F.unfold(\n",
        "        features, kernel_size=kernel_size, dilation=dilation, padding=_pad, stride=stride) \\\n",
        "        .reshape(B, C, kernel_size ** 2, H * W)\n",
        "\n",
        "    if ghost_mul is not None:\n",
        "        ghost_mul = ghost_mul.reshape(B, C, kernel_size ** 2, 1)\n",
        "    if ghost_add is not None:\n",
        "        ghost_add = ghost_add.reshape(B, C, kernel_size ** 2, 1)\n",
        "\n",
        "    h_attn = h_attn.reshape(B, 1, kernel_size ** 2, H * W)\n",
        "\n",
        "    # Compute filters\n",
        "    if ghost_mul is not None and ghost_add is not None:\n",
        "        filters = ghost_mul * h_attn + ghost_add\n",
        "    elif ghost_mul is not None:\n",
        "        filters = ghost_mul * h_attn\n",
        "    elif ghost_add is not None:\n",
        "        filters = h_attn + ghost_add\n",
        "    else:\n",
        "        filters = h_attn\n",
        "\n",
        "    return (features_unfolded * filters).sum(2).reshape(B, C, H, W)\n",
        "\n",
        "class ELSA(nn.Module):\n",
        "    \"\"\"Standard Enhanced Local Self-Attention\"\"\"\n",
        "    def __init__(self, dim, num_heads, dim_qk=None, dim_v=None, kernel_size=5,\n",
        "                 stride=1, dilation=1, qkv_bias=False, qk_scale=None,\n",
        "                 attn_drop=0., proj_drop=0., group_width=8, groups=1, lam=1,\n",
        "                 gamma=1, **kwargs):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        self.dim_qk = dim_qk or self.dim // 3 * 2\n",
        "        self.dim_v = dim_v or dim\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.dilation = dilation\n",
        "\n",
        "        head_dim = self.dim_v // num_heads\n",
        "        self.scale = qk_scale or head_dim ** -0.5\n",
        "\n",
        "        if self.dim_qk % group_width != 0:\n",
        "            self.dim_qk = math.ceil(float(self.dim_qk) / group_width) * group_width\n",
        "\n",
        "        self.group_width = group_width\n",
        "        self.groups = groups\n",
        "        self.lam = lam\n",
        "        self.gamma = gamma\n",
        "\n",
        "        self.pre_proj = nn.Conv2d(dim, self.dim_qk * 2 + self.dim_v, 1, bias=qkv_bias)\n",
        "        self.attn = nn.Sequential(\n",
        "            nn.Conv2d(self.dim_qk, self.dim_qk, kernel_size, padding=(kernel_size // 2)*dilation,\n",
        "                      dilation=dilation, groups=self.dim_qk // group_width),\n",
        "            nn.GELU(),\n",
        "            nn.Conv2d(self.dim_qk, kernel_size ** 2 * num_heads, 1, groups=groups))\n",
        "\n",
        "        if self.lam != 0 and self.gamma != 0:\n",
        "            ghost_mul = torch.randn(1, 1, self.dim_v, kernel_size, kernel_size)\n",
        "            ghost_add = torch.zeros(1, 1, self.dim_v, kernel_size, kernel_size)\n",
        "            trunc_normal_(ghost_add, std=.02)\n",
        "            self.ghost_head = nn.Parameter(torch.cat((ghost_mul, ghost_add), dim=0), requires_grad=True)\n",
        "        elif self.lam == 0 and self.gamma != 0:\n",
        "            ghost_add = torch.zeros(1, self.dim_v, kernel_size, kernel_size)\n",
        "            trunc_normal_(ghost_add, std=.02)\n",
        "            self.ghost_head = nn.Parameter(ghost_add, requires_grad=True)\n",
        "        elif self.lam != 0 and self.gamma == 0:\n",
        "            ghost_mul = torch.randn(1, self.dim_v, kernel_size, kernel_size)\n",
        "            self.ghost_head = nn.Parameter(ghost_mul, requires_grad=True)\n",
        "        else:\n",
        "            self.ghost_head = None\n",
        "\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.post_proj = nn.Linear(self.dim_v, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        B, H, W, _ = x.shape\n",
        "        C = self.dim_v\n",
        "        ks = self.kernel_size\n",
        "        G = self.num_heads\n",
        "        x = x.permute(0, 3, 1, 2)  # B, C, H, W\n",
        "\n",
        "        qkv = self.pre_proj(x)\n",
        "        q, k, v = torch.split(qkv, (self.dim_qk, self.dim_qk, self.dim_v), dim=1)\n",
        "        hadamard_product = q * k * self.scale\n",
        "\n",
        "        if self.stride > 1:\n",
        "            hadamard_product = F.avg_pool2d(hadamard_product, self.stride)\n",
        "\n",
        "        h_attn = self.attn(hadamard_product)\n",
        "        v = v.reshape(B * G, C // G, H, W)\n",
        "        h_attn = h_attn.reshape(B * G, -1, H, W).softmax(1)\n",
        "        h_attn = self.attn_drop(h_attn)\n",
        "\n",
        "        ghost_mul = None\n",
        "        ghost_add = None\n",
        "        if self.lam != 0 and self.gamma != 0:\n",
        "            gh = self.ghost_head.expand(2, B, C, ks, ks).reshape(2, B * G, C // G, ks, ks)\n",
        "            ghost_mul, ghost_add = gh[0], gh[1]\n",
        "        elif self.lam == 0 and self.gamma != 0:\n",
        "            ghost_add = self.ghost_head.expand(B, C, ks, ks).reshape(B * G, C // G, ks, ks)\n",
        "        elif self.lam != 0 and self.gamma == 0:\n",
        "            ghost_mul = self.ghost_head.expand(B, C, ks, ks).reshape(B * G, C // G, ks, ks)\n",
        "\n",
        "        x = elsa_op(v, ghost_mul, ghost_add, h_attn, self.lam, self.gamma,\n",
        "                    self.kernel_size, self.dilation, self.stride)\n",
        "        x = x.reshape(B, C, H // self.stride, W // self.stride)\n",
        "        x = self.post_proj(x.permute(0, 2, 3, 1))  # B, H, W, C\n",
        "        x = self.proj_drop(x)\n",
        "        return x\n",
        "\n",
        "class ELSABlock(nn.Module):\n",
        "    \"\"\"Standard ELSA block: ELSA + MLP\"\"\"\n",
        "    def __init__(self, dim, kernel_size, stride=1, num_heads=1, mlp_ratio=3.,\n",
        "                 drop=0., attn_drop=0., drop_path=0., act_layer=nn.GELU,\n",
        "                 norm_layer=nn.LayerNorm, qkv_bias=False, qk_scale=1,\n",
        "                 dim_qk=None, dim_v=None, lam=1, gamma=1, dilation=1,\n",
        "                 group_width=8, groups=1, **kwargs):\n",
        "        super().__init__()\n",
        "        assert stride == 1\n",
        "        self.dim = dim\n",
        "        self.norm1 = norm_layer(dim)\n",
        "        self.attn = ELSA(dim, num_heads, dim_qk=dim_qk, dim_v=dim_v,\n",
        "                         kernel_size=kernel_size, stride=stride, dilation=dilation,\n",
        "                         qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop,\n",
        "                         group_width=group_width, groups=groups, lam=lam, gamma=gamma)\n",
        "\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
        "        self.norm2 = norm_layer(dim)\n",
        "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
        "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim,\n",
        "                       act_layer=act_layer, drop=drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path(self.attn(self.norm1(x)))\n",
        "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
        "        return x\n",
        "\n",
        "print(\"‚úÖ Standard ELSA implementation loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxxXsXA-ZmOo",
        "outputId": "72a5a15c-5d68-44d1-f81d-4e6dad2c3403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ViT base components loaded\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Cell 7: Vision Transformer Base Components\n",
        "# ============================================================\n",
        "\n",
        "class PatchEmbed(nn.Module):\n",
        "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=384):\n",
        "        super().__init__()\n",
        "        assert img_size % patch_size == 0\n",
        "        self.num_patches = (img_size // patch_size) * (img_size // patch_size)\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.proj(x)  # (B, C, H/ps, W/ps)\n",
        "        x = x.flatten(2).transpose(1, 2)  # (B, N, C)\n",
        "        return x\n",
        "\n",
        "class AdaptiveAttention(nn.Module):\n",
        "    def __init__(self, dim, num_heads=6, qkv_bias=True, attn_drop=0., proj_drop=0.,\n",
        "                 ada_head=False, head_select_tau=5.0):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = dim // num_heads\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "        self.ada_head = ada_head\n",
        "        self.head_select_tau = head_select_tau\n",
        "\n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "        if ada_head:\n",
        "            self.head_select = nn.Linear(dim, num_heads)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "        attn_scores = (q @ k.transpose(-2, -1)) * self.scale\n",
        "\n",
        "        head_policy = None\n",
        "        if self.ada_head:\n",
        "            cls_embed = x[:, 0]\n",
        "            logits = self.head_select(cls_embed)\n",
        "            head_policy = F.gumbel_softmax(logits / self.head_select_tau, hard=True, dim=-1)\n",
        "            attn_scores = attn_scores * head_policy.unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "        attn = attn_scores.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        out = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        out = self.proj(out)\n",
        "        out = self.proj_drop(out)\n",
        "        return out, head_policy\n",
        "\n",
        "class AdaptiveBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=True, drop=0.,\n",
        "                 attn_drop=0., drop_path=0., ada_head=False, head_select_tau=5.0):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.attn = AdaptiveAttention(\n",
        "            dim, num_heads=num_heads, qkv_bias=qkv_bias, attn_drop=attn_drop,\n",
        "            proj_drop=drop, ada_head=ada_head, head_select_tau=head_select_tau\n",
        "        )\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0 else nn.Identity()\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "\n",
        "        hidden_dim = int(dim * mlp_ratio)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(drop),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "            nn.Dropout(drop),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_in = self.norm1(x)\n",
        "        attn_out, head_policy = self.attn(attn_in)\n",
        "        x = x + self.drop_path(attn_out)\n",
        "\n",
        "        mlp_in = self.norm2(x)\n",
        "        x = x + self.drop_path(self.mlp(mlp_in))\n",
        "\n",
        "        return x, head_policy\n",
        "\n",
        "print(\"‚úÖ ViT base components loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFF0hg6PZ4WW",
        "outputId": "6d21710f-cebf-4155-a5a2-5689140eed4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ MedicalAdaptiveViT model loaded\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Cell 8: Medical Adaptive ViT Main Model\n",
        "# ============================================================\n",
        "\n",
        "class MedicalAdaptiveViT(nn.Module):\n",
        "    def __init__(self, img_size=224, patch_size=16, in_chans=3, num_classes=1000,\n",
        "                 embed_dim=384, depth=8, num_heads=6, mlp_ratio=4.,\n",
        "                 drop_rate=0.1, drop_path_rate=0.1, ada_head=False, ada_layer=False,\n",
        "                 head_select_tau=5.0, layer_select_tau=5.0,\n",
        "                 use_pathoscale=True, use_standard_elsa=False,\n",
        "                 pathoscale_kernel_sizes=[3, 5, 7], pathoscale_num_heads=6,\n",
        "                 pathoscale_mlp_ratio=3.0, pathoscale_lam=1.0, pathoscale_gamma=1.0,\n",
        "                 medical_prior=True, cross_scale_fusion=True, pathology_guided=True,\n",
        "                 # Standard ELSA parameters (for backward compatibility)\n",
        "                 elsa_kernel_size=5, elsa_num_heads=6, elsa_mlp_ratio=3.0,\n",
        "                 elsa_lam=1.0, elsa_gamma=1.0):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.embed_dim = embed_dim\n",
        "        self.depth = depth\n",
        "        self.ada_head = ada_head\n",
        "        self.ada_layer = ada_layer\n",
        "        self.layer_select_tau = layer_select_tau\n",
        "        self.use_pathoscale = use_pathoscale\n",
        "        self.use_standard_elsa = use_standard_elsa\n",
        "\n",
        "        self.patch_embed = PatchEmbed(img_size, patch_size, in_chans, embed_dim)\n",
        "        num_patches = self.patch_embed.num_patches\n",
        "\n",
        "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n",
        "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
        "\n",
        "        # Enhanced Medical ELSA block after patch embedding\n",
        "        if use_pathoscale:\n",
        "            self.pathoscale_block = PathoScaleSABlock(\n",
        "                dim=embed_dim, num_heads=pathoscale_num_heads,\n",
        "                kernel_sizes=pathoscale_kernel_sizes, mlp_ratio=pathoscale_mlp_ratio,\n",
        "                drop=drop_rate, attn_drop=0.0, drop_path=0.0,\n",
        "                medical_prior=medical_prior, cross_scale_fusion=cross_scale_fusion,\n",
        "                pathology_guided=pathology_guided, lam=pathoscale_lam, gamma=pathoscale_gamma\n",
        "            )\n",
        "        elif use_standard_elsa:\n",
        "            # Standard ELSA block for comparison\n",
        "            self.elsa_block = ELSABlock(\n",
        "                dim=embed_dim, kernel_size=elsa_kernel_size, num_heads=elsa_num_heads,\n",
        "                mlp_ratio=elsa_mlp_ratio, drop=drop_rate, attn_drop=0.0,\n",
        "                drop_path=0.0, lam=elsa_lam, gamma=elsa_gamma\n",
        "            )\n",
        "\n",
        "        # Adaptive Vision Transformer blocks\n",
        "        dpr = torch.linspace(0, drop_path_rate, steps=depth).tolist()\n",
        "        self.blocks = nn.ModuleList([\n",
        "            AdaptiveBlock(\n",
        "                embed_dim, num_heads, mlp_ratio=mlp_ratio, qkv_bias=True,\n",
        "                drop=drop_rate, attn_drop=0.0, drop_path=dpr[i], ada_head=ada_head,\n",
        "                head_select_tau=head_select_tau\n",
        "            ) for i in range(depth)\n",
        "        ])\n",
        "\n",
        "        if ada_layer:\n",
        "            self.layer_select = nn.Linear(embed_dim, depth)\n",
        "\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "        self.head = nn.Linear(embed_dim, num_classes)\n",
        "\n",
        "        trunc_normal_(self.pos_embed, std=0.02)\n",
        "        trunc_normal_(self.cls_token, std=0.02)\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    @staticmethod\n",
        "    def _init_weights(m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            trunc_normal_(m.weight, std=0.02)\n",
        "            if m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "            nn.init.constant_(m.weight, 1.0)\n",
        "\n",
        "    def forward_features(self, x):\n",
        "        B = x.shape[0]\n",
        "        x = self.patch_embed(x)\n",
        "        cls = self.cls_token.expand(B, -1, -1)\n",
        "        x = torch.cat([cls, x], dim=1)\n",
        "        x = x + self.pos_embed\n",
        "        x = self.pos_drop(x)\n",
        "\n",
        "        # Apply Enhanced Medical ELSA or Standard ELSA after patch embedding\n",
        "        if self.use_pathoscale:\n",
        "            patch_dim = int(math.sqrt(x.shape[1] - 1))\n",
        "            cls_token = x[:, 0:1, :]\n",
        "            patch_tokens = x[:, 1:, :]\n",
        "\n",
        "            # Reshape to spatial format for PathoScaleSA\n",
        "            patch_tokens = patch_tokens.reshape(B, patch_dim, patch_dim, self.embed_dim)\n",
        "            patch_tokens = self.pathoscale_block(patch_tokens)\n",
        "            patch_tokens = patch_tokens.reshape(B, patch_dim * patch_dim, self.embed_dim)\n",
        "\n",
        "            # Concatenate CLS token back\n",
        "            x = torch.cat([cls_token, patch_tokens], dim=1)\n",
        "\n",
        "        elif self.use_standard_elsa:\n",
        "            patch_dim = int(math.sqrt(x.shape[1] - 1))\n",
        "            cls_token = x[:, 0:1, :]\n",
        "            patch_tokens = x[:, 1:, :]\n",
        "\n",
        "            # Reshape to spatial format for Standard ELSA\n",
        "            patch_tokens = patch_tokens.reshape(B, patch_dim, patch_dim, self.embed_dim)\n",
        "            patch_tokens = self.elsa_block(patch_tokens)\n",
        "            patch_tokens = patch_tokens.reshape(B, patch_dim * patch_dim, self.embed_dim)\n",
        "\n",
        "            # Concatenate CLS token back\n",
        "            x = torch.cat([cls_token, patch_tokens], dim=1)\n",
        "\n",
        "        head_policies = []\n",
        "        layer_policy = None\n",
        "\n",
        "        if self.ada_layer:\n",
        "            with torch.no_grad():\n",
        "                logits = self.layer_select(x[:, 0])\n",
        "                layer_policy = F.gumbel_softmax(logits / self.layer_select_tau, hard=True, dim=-1)\n",
        "\n",
        "        for i, blk in enumerate(self.blocks):\n",
        "            if self.ada_layer and layer_policy is not None:\n",
        "                if (layer_policy[:, i].sum() == 0):\n",
        "                    head_policies.append(None)\n",
        "                    continue\n",
        "            x, h_pol = blk(x)\n",
        "            head_policies.append(h_pol)\n",
        "\n",
        "        x = self.norm(x)\n",
        "        return x[:, 0], head_policies, layer_policy\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats, head_policies, layer_policy = self.forward_features(x)\n",
        "        logits = self.head(feats)\n",
        "\n",
        "        head_select = None\n",
        "        if self.ada_head and any(p is not None for p in head_policies):\n",
        "            valid = [p for p in head_policies if p is not None]\n",
        "            if len(valid) > 0:\n",
        "                head_select = torch.stack(valid, dim=1).mean(dim=1)\n",
        "\n",
        "        return logits, head_select, layer_policy\n",
        "\n",
        "print(\"‚úÖ MedicalAdaptiveViT model loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTDKsymMcxjX",
        "outputId": "9d727382-3c5e-4f5c-c090-95fafe8f9d39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "STABLE CONFIG WITH MEDICAL FEATURES\n",
            "============================================================\n",
            "‚úÖ Medical features: ALL ENABLED\n",
            "‚úÖ Max LR: 0.00015 (reduced from 0.0006)\n",
            "‚úÖ Gradient clipping: 1.0 (stronger)\n",
            "‚úÖ Starting fresh training with stable parameters\n",
            "‚úÖ Device set to: cuda\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Step 1: Update Config (Replace your Cell 10)\n",
        "# ============================================================\n",
        "\n",
        "from dataclasses import dataclass\n",
        "import os\n",
        "import torch\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    train_csv = \"/content/drive/MyDrive/SkinDiseaseProject/train_dataset.csv\"\n",
        "    test_csv = \"/content/drive/MyDrive/SkinDiseaseProject/test_dataset.csv\"\n",
        "\n",
        "    img_size = 224\n",
        "    batch_size = 24\n",
        "    num_workers = 2\n",
        "    pin_memory = True\n",
        "\n",
        "    # Model\n",
        "    patch_size = 16\n",
        "    embed_dim = 384\n",
        "    depth = 8\n",
        "    num_heads = 6\n",
        "    mlp_ratio = 4.0\n",
        "    drop_rate = 0.1\n",
        "    drop_path_rate = 0.1\n",
        "\n",
        "    # PathoScaleSA\n",
        "    use_pathoscale = True\n",
        "    use_standard_elsa = False\n",
        "    pathoscale_kernel_sizes = [3, 5, 7]\n",
        "    pathoscale_num_heads = 6\n",
        "    pathoscale_mlp_ratio = 3.0\n",
        "    pathoscale_lam = 1.0\n",
        "    pathoscale_gamma = 1.0\n",
        "\n",
        "    # üéØ MEDICAL FEATURES: ENABLED with STABLE LR\n",
        "    medical_prior = True\n",
        "    cross_scale_fusion = True\n",
        "    pathology_guided = False\n",
        "\n",
        "    # Standard ELSA\n",
        "    elsa_kernel_size = 5\n",
        "    elsa_num_heads = 6\n",
        "    elsa_mlp_ratio = 3.0\n",
        "    elsa_lam = 1.0\n",
        "    elsa_gamma = 1.0\n",
        "\n",
        "    # üîß FIXED TRAINING PARAMETERS\n",
        "    epochs = 67\n",
        "    lr = 5e-5 # Base LR\n",
        "    base_lr = 5e-5 # Add base_lr to config\n",
        "    weight_decay = 0.05\n",
        "    max_lr = 1.5e-4\n",
        "\n",
        "    gradient_accumulation_steps = 6\n",
        "    max_grad_norm = 1.0\n",
        "    use_amp = True\n",
        "\n",
        "    # Checkpointing\n",
        "    save_every = 5 # Added save_every attribute\n",
        "    ckpt_dir = \"/content/drive/MyDrive/SkinDiseaseProject/checkpoints\"\n",
        "    best_ckpt_path = \"/content/drive/MyDrive/SkinDiseaseProject/best_model_stable.pth\"\n",
        "\n",
        "    # Logging\n",
        "    log_every = 300\n",
        "    plot_path = \"/content/drive/MyDrive/SkinDiseaseProject/training_curves.png\"\n",
        "    results_dir = \"/content/drive/MyDrive/SkinDiseaseProject/results\"\n",
        "\n",
        "    patience = 7\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    def __post_init__(self):\n",
        "        import os\n",
        "        os.makedirs(self.ckpt_dir, exist_ok=True)\n",
        "        os.makedirs(self.results_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "config = Config()\n",
        "config.__post_init__()\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"STABLE CONFIG WITH MEDICAL FEATURES\")\n",
        "print(\"=\"*60)\n",
        "print(f\"‚úÖ Medical features: ALL ENABLED\")\n",
        "print(f\"‚úÖ Max LR: {config.max_lr} (reduced from 0.0006)\")\n",
        "print(f\"‚úÖ Gradient clipping: {config.max_grad_norm} (stronger)\")\n",
        "print(f\"‚úÖ Starting fresh training with stable parameters\")\n",
        "print(f\"‚úÖ Device set to: {config.device}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4579d31",
        "outputId": "5bbd94bd-83ae-4310-9b04-4db3eebc1047"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ GPU is available!\n",
            "GPU Name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"‚úÖ GPU is available!\")\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"‚ùå GPU is NOT available.\")\n",
        "    print(\"Go to Runtime > Change runtime type and select a GPU as the hardware accelerator.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eg83KaduUpib",
        "outputId": "316c244a-1f58-4400-bb7d-5b8974fc8776"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "üîß FIXING SCHEDULER COMPATIBILITY ISSUE\n",
            "================================================================================\n",
            "\n",
            "üì¶ Found 2 checkpoint files\n",
            "‚ÑπÔ∏è  Backup already exists at: /content/drive/MyDrive/SkinDiseaseProject/checkpoints_old_scheduler_backup\n",
            "üóëÔ∏è  Cleared checkpoint directory for fresh training with CyclicLR\n",
            "\n",
            "================================================================================\n",
            "‚úÖ READY TO START TRAINING WITH NEW LEARNING RATE SCHEDULE\n",
            "================================================================================\n",
            "\n",
            "üéØ Target Configuration:\n",
            "   Base LR: 1e-5\n",
            "   Max LR: 8e-4\n",
            "   Scheduler: CyclicLR (Triangular)\n",
            "   Batch Size: 24\n",
            "   Gradient Accumulation: 6 steps\n",
            "   Effective Batch Size: 144\n",
            "   Epochs: 50\n",
            "\n",
            "üéØ Expected Improvement: 70% ‚Üí 78-85% accuracy\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CELL: Fix Scheduler Checkpoint Issue - Add This BEFORE Training\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"üîß FIXING SCHEDULER COMPATIBILITY ISSUE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "checkpoint_dir = '/content/drive/MyDrive/SkinDiseaseProject/checkpoints'\n",
        "backup_dir = '/content/drive/MyDrive/SkinDiseaseProject/checkpoints_old_scheduler_backup'\n",
        "\n",
        "# Backup old checkpoints\n",
        "if os.path.exists(checkpoint_dir):\n",
        "    checkpoint_files = os.listdir(checkpoint_dir)\n",
        "    if checkpoint_files:\n",
        "        print(f\"\\nüì¶ Found {len(checkpoint_files)} checkpoint files\")\n",
        "\n",
        "        # Create backup\n",
        "        if not os.path.exists(backup_dir):\n",
        "            shutil.copytree(checkpoint_dir, backup_dir)\n",
        "            print(f\"‚úÖ Backed up old checkpoints to: {backup_dir}\")\n",
        "        else:\n",
        "            print(f\"‚ÑπÔ∏è  Backup already exists at: {backup_dir}\")\n",
        "\n",
        "        # Clear current checkpoints\n",
        "        shutil.rmtree(checkpoint_dir)\n",
        "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "        print(f\"üóëÔ∏è  Cleared checkpoint directory for fresh training with CyclicLR\")\n",
        "    else:\n",
        "        print(\"‚ÑπÔ∏è  No existing checkpoints found\")\n",
        "else:\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "    print(\"‚úÖ Created fresh checkpoint directory\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ READY TO START TRAINING WITH NEW LEARNING RATE SCHEDULE\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nüéØ Target Configuration:\")\n",
        "print(f\"   Base LR: 1e-5\")\n",
        "print(f\"   Max LR: 8e-4\")\n",
        "print(f\"   Scheduler: CyclicLR (Triangular)\")\n",
        "print(f\"   Batch Size: 24\")\n",
        "print(f\"   Gradient Accumulation: 6 steps\")\n",
        "print(f\"   Effective Batch Size: 144\")\n",
        "print(f\"   Epochs: 50\")\n",
        "print(f\"\\nüéØ Expected Improvement: 70% ‚Üí 78-85% accuracy\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jm4swFmQaHT4",
        "outputId": "46a8fbc4-d184-4740-a02d-9703d247289d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "‚úÖ Auto-resume training utilities loaded!\n",
            "============================================================\n",
            "Features:\n",
            "  ‚úÖ NaN handling (skips, doesn't stop)\n",
            "  ‚úÖ Auto-save every epoch\n",
            "  ‚úÖ Auto-resume if interrupted\n",
            "  ‚úÖ Periodic checkpoints\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CELL: Training Utilities with Auto-Save & Resume\n",
        "# ============================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "import torch.serialization # Import serialization module\n",
        "\n",
        "def train_one_epoch(model, train_loader, optimizer, scheduler, scaler, epoch, config):\n",
        "    \"\"\"Training loop for one epoch with NaN protection (non-blocking)\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    nan_count = 0\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        # Skip batch if collate_fn returned None\n",
        "        if images is None:\n",
        "            print(f\"‚ö†Ô∏è Skipped empty batch at Epoch {epoch}, Batch {batch_idx}\")\n",
        "            continue\n",
        "\n",
        "        images, labels = images.to(config.device), labels.to(config.device)\n",
        "\n",
        "        # Use autocast and scaler only if AMP is enabled and device is CUDA\n",
        "        if config.use_amp and config.device.startswith('cuda'):\n",
        "            with torch.amp.autocast('cuda', enabled=config.use_amp):\n",
        "                logits, local_attn, global_attn = model(images)\n",
        "                loss = F.cross_entropy(logits, labels)\n",
        "            loss = loss / config.gradient_accumulation_steps\n",
        "            # NaN detection - skip batch instead of stopping\n",
        "            if torch.isnan(loss):\n",
        "                print(f\"‚ö†Ô∏è NaN at Epoch {epoch}, Batch {batch_idx}, skipping...\")\n",
        "                nan_count += 1\n",
        "                optimizer.zero_grad()\n",
        "                continue\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            if (batch_idx + 1) % config.gradient_accumulation_steps == 0:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad()\n",
        "                scheduler.step()\n",
        "        else: # Standard training loop for CPU or AMP disabled\n",
        "            logits, local_attn, global_attn = model(images)\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "            loss = loss / config.gradient_accumulation_steps\n",
        "            # NaN detection - skip batch instead of stopping\n",
        "            if torch.isnan(loss):\n",
        "                print(f\"‚ö†Ô∏è NaN at Epoch {epoch}, Batch {batch_idx}, skipping...\")\n",
        "                nan_count += 1\n",
        "                optimizer.zero_grad()\n",
        "                continue\n",
        "\n",
        "            loss.backward()\n",
        "            if (batch_idx + 1) % config.gradient_accumulation_steps == 0:\n",
        "              scaler.unscale_(optimizer)\n",
        "              torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
        "              scaler.step(optimizer)\n",
        "              scaler.update()\n",
        "              optimizer.zero_grad()\n",
        "              scheduler.step()  # ‚Üê This is correct for CyclicLR (per batch)\n",
        "\n",
        "\n",
        "        total_loss += loss.item() * config.gradient_accumulation_steps\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        if (batch_idx + 1) % config.log_every == 0:\n",
        "            acc = 100. * correct / total if total > 0 else 0\n",
        "            avg_loss = total_loss / (batch_idx + 1)\n",
        "            print(f\"  Epoch [{epoch}/{config.epochs}] \"\n",
        "                  f\"Batch [{batch_idx+1}/{len(train_loader)}] \"\n",
        "                  f\"Loss: {avg_loss:.4f} \"\n",
        "                  f\"Acc: {acc:.2f}% \"\n",
        "                  f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "        if batch_idx % 100 == 0 and config.device.startswith('cuda'):\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    epoch_loss = total_loss / len(train_loader) if len(train_loader) > 0 else 0\n",
        "    epoch_acc = 100. * correct / total if total > 0 else 0\n",
        "\n",
        "    if nan_count > 0:\n",
        "        print(f\"‚ö†Ô∏è {nan_count} NaN batches skipped (training continues)\")\n",
        "\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "def validate(model, val_loader, device):\n",
        "    \"\"\"Validation function\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            # Skip batch if collate_fn returned None\n",
        "            if images is None:\n",
        "                continue\n",
        "\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            logits, _, _ = model(images)\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "            total_loss += loss.item()\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    val_loss = total_loss / len(val_loader) if len(val_loader) > 0 else 0\n",
        "    val_acc = 100. * correct / total if total > 0 else 0\n",
        "    return val_loss, val_acc\n",
        "\n",
        "\n",
        "def plot_training_curves(history, save_path):\n",
        "    \"\"\"Plot training curves\"\"\"\n",
        "    epochs = range(1, len(history['train_loss']) + 1)\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    axes[0].plot(epochs, history['train_loss'], 'b-o', label='Train Loss', linewidth=2)\n",
        "    axes[0].plot(epochs, history['val_loss'], 'r-s', label='Val Loss', linewidth=2)\n",
        "    axes[0].set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "    axes[0].set_ylabel('Loss', fontsize=12, fontweight='bold')\n",
        "    axes[0].set_title('Training & Validation Loss', fontsize=14, fontweight='bold')\n",
        "    axes[0].legend(fontsize=11)\n",
        "    axes[0].grid(alpha=0.3)\n",
        "\n",
        "    axes[1].plot(epochs, history['train_acc'], 'b-o', label='Train Acc', linewidth=2)\n",
        "    axes[1].plot(epochs, history['val_acc'], 'r-s', label='Val Acc', linewidth=2)\n",
        "    axes[1].set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "    axes[1].set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
        "    axes[1].set_title('Training & Validation Accuracy', fontsize=14, fontweight='bold')\n",
        "    axes[1].legend(fontsize=11)\n",
        "    axes[1].grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"‚úÖ Curves saved: {save_path}\")\n",
        "\n",
        "\n",
        "def save_checkpoint(model, optimizer, scheduler, epoch, val_acc, history, config, label_names, is_best=False):\n",
        "    \"\"\"Save checkpoint for resuming\"\"\"\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scheduler_state_dict': scheduler.state_dict(),\n",
        "        'val_acc': val_acc,\n",
        "        'history': history,\n",
        "        'label_names': label_names,\n",
        "        'config': config\n",
        "    }\n",
        "\n",
        "    # Save latest checkpoint\n",
        "    latest_path = f\"{config.ckpt_dir}/latest_checkpoint.pth\"\n",
        "    torch.save(checkpoint, latest_path)\n",
        "\n",
        "    # Save best model\n",
        "    if is_best:\n",
        "        torch.save(checkpoint, config.best_ckpt_path)\n",
        "        print(f\"‚úÖ Best model saved: {val_acc:.2f}%\")\n",
        "\n",
        "    # Save periodic checkpoint\n",
        "    if epoch % config.save_every == 0:\n",
        "        epoch_path = f\"{config.ckpt_dir}/epoch_{epoch}.pth\"\n",
        "        torch.save(checkpoint, epoch_path)\n",
        "        print(f\"üíæ Checkpoint saved: epoch_{epoch}.pth\")\n",
        "\n",
        "\n",
        "def load_checkpoint_if_exists(config):\n",
        "    \"\"\"Load latest checkpoint if available\"\"\"\n",
        "    latest_path = f\"{config.ckpt_dir}/latest_checkpoint.pth\"\n",
        "\n",
        "    if os.path.exists(latest_path):\n",
        "        print(f\"‚úÖ Found checkpoint: {latest_path}\")\n",
        "        print(\"üîÑ Resuming training...\")\n",
        "        # Allowlist the Config class for safe loading\n",
        "        torch.serialization.add_safe_globals([Config])\n",
        "        return torch.load(latest_path, map_location=config.device)\n",
        "    else:\n",
        "        print(\"üí° No checkpoint found - starting fresh\")\n",
        "        return None\n",
        "\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"‚úÖ Auto-resume training utilities loaded!\")\n",
        "print(\"=\"*60)\n",
        "print(\"Features:\")\n",
        "print(\"  ‚úÖ NaN handling (skips, doesn't stop)\")\n",
        "print(\"  ‚úÖ Auto-save every epoch\")\n",
        "print(\"  ‚úÖ Auto-resume if interrupted\")\n",
        "print(\"  ‚úÖ Periodic checkpoints\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHmBvKpla5zT"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL: Main Training with Auto-Resume (COMPLETE VERSION)\n",
        "# ============================================================\n",
        "from torch.optim.lr_scheduler import CyclicLR\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "import torch.serialization\n",
        "\n",
        "def main_training_continuous():\n",
        "    \"\"\"Training that survives disconnections and resumes automatically\"\"\"\n",
        "\n",
        "    config = Config()\n",
        "\n",
        "    # Inform the user about the device being used\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"‚úÖ GPU is available! Using device: {config.device}\")\n",
        "        print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\\n\")\n",
        "    else:\n",
        "        print(f\"‚ùå GPU is NOT available. Using device: {config.device}\\n\")\n",
        "\n",
        "    # Load data\n",
        "    train_df = pd.read_csv(config.train_csv)\n",
        "    test_df = pd.read_csv(config.test_csv)\n",
        "    num_classes = train_df['label'].nunique()\n",
        "    label_names = sorted(train_df['label'].unique())\n",
        "\n",
        "    print(f\"üìä Classes: {num_classes}, Train: {len(train_df):,}, Test: {len(test_df):,}\\n\")\n",
        "\n",
        "    # Create datasets\n",
        "    preprocessor = SimpleMedicalImagePreprocessor(img_size=config.img_size)\n",
        "    train_transform = preprocessor.get_train_transforms()\n",
        "    val_transform = preprocessor.get_val_transforms()\n",
        "\n",
        "    # Custom collate function\n",
        "    def collate_fn(batch):\n",
        "        batch = [(img, label) for img, label in batch if img is not None and label is not None]\n",
        "        if not batch:\n",
        "            return None, None\n",
        "        return torch.utils.data.dataloader.default_collate(batch)\n",
        "\n",
        "    train_dataset = CustomImageDataset(config.train_csv, transform=train_transform)\n",
        "    val_dataset = CustomImageDataset(config.test_csv, transform=val_transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n",
        "                             shuffle=True, num_workers=config.num_workers,\n",
        "                             pin_memory=config.pin_memory, drop_last=True,\n",
        "                             collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=config.batch_size,\n",
        "                           shuffle=False, num_workers=config.num_workers,\n",
        "                           pin_memory=config.pin_memory,\n",
        "                           collate_fn=collate_fn)\n",
        "\n",
        "    # Create model\n",
        "    print(\"üèóÔ∏è Building model...\")\n",
        "    model = MedicalAdaptiveViT(\n",
        "        img_size=config.img_size, patch_size=config.patch_size,\n",
        "        num_classes=num_classes, embed_dim=config.embed_dim,\n",
        "        depth=config.depth, num_heads=config.num_heads,\n",
        "        mlp_ratio=config.mlp_ratio, drop_rate=config.drop_rate,\n",
        "        drop_path_rate=config.drop_path_rate,\n",
        "        use_pathoscale=config.use_pathoscale,\n",
        "        pathoscale_kernel_sizes=config.pathoscale_kernel_sizes,\n",
        "        pathoscale_num_heads=config.pathoscale_num_heads,\n",
        "        medical_prior=config.medical_prior,\n",
        "        cross_scale_fusion=config.cross_scale_fusion,\n",
        "        pathology_guided=config.pathology_guided\n",
        "    ).to(config.device)\n",
        "\n",
        "    print(f\"‚úÖ Parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\\n\")\n",
        "\n",
        "    # Calculate steps per epoch\n",
        "    steps_per_epoch = len(train_loader) // config.gradient_accumulation_steps\n",
        "\n",
        "    # Optimizer & scheduler\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=config.base_lr,\n",
        "        weight_decay=config.weight_decay,\n",
        "        betas=(0.9, 0.999)\n",
        "    )\n",
        "\n",
        "    scheduler = CyclicLR(\n",
        "        optimizer,\n",
        "        base_lr=config.base_lr,\n",
        "        max_lr=config.max_lr,\n",
        "        step_size_up=steps_per_epoch * 2,\n",
        "        mode='triangular',\n",
        "        cycle_momentum=False\n",
        "    )\n",
        "\n",
        "    # Initialize GradScaler\n",
        "    scaler = None\n",
        "    if config.use_amp and config.device.startswith('cuda'):\n",
        "        scaler = torch.amp.GradScaler(enabled=True)\n",
        "\n",
        "    # ============================================================\n",
        "    # TRY TO RESUME FROM CHECKPOINT\n",
        "    # ============================================================\n",
        "    checkpoint_path = os.path.join(config.ckpt_dir, 'latest_checkpoint.pth')\n",
        "    start_epoch = 1\n",
        "    best_val_acc = 0\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'learning_rates': []}\n",
        "\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        try:\n",
        "            print(f\"‚úÖ Found checkpoint: {checkpoint_path}\")\n",
        "            print(\"üîÑ Resuming training...\")\n",
        "\n",
        "            # Add safe globals for Config class\n",
        "            torch.serialization.add_safe_globals([Config])\n",
        "\n",
        "            checkpoint = torch.load(checkpoint_path, map_location=config.device, weights_only=False)\n",
        "\n",
        "            # Load model state\n",
        "            model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
        "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "            # Load scheduler if exists\n",
        "            if 'scheduler_state_dict' in checkpoint:\n",
        "                scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "\n",
        "            start_epoch = checkpoint['epoch'] + 1\n",
        "            best_val_acc = checkpoint.get('best_val_acc', checkpoint.get('val_acc', 0))\n",
        "            history = checkpoint.get('history', history)\n",
        "\n",
        "            print(f\"‚úÖ Resumed from epoch {checkpoint['epoch']}\")\n",
        "            print(f\"üìä Best accuracy so far: {best_val_acc:.2f}%\\n\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Could not load checkpoint: {e}\")\n",
        "            print(\"üí° Starting training from scratch (epoch 1).\\n\")\n",
        "            start_epoch = 1\n",
        "            best_val_acc = 0\n",
        "            history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'learning_rates': []}\n",
        "    else:\n",
        "        print(\"üí° No checkpoint found - starting fresh from epoch 1.\\n\")\n",
        "\n",
        "    # ============================================================\n",
        "    # TRAINING LOOP\n",
        "    # ============================================================\n",
        "    print(\"üöÄ Starting training...\\n\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    start_time = time.time()\n",
        "    patience_counter = 0\n",
        "    epoch = start_epoch - 1\n",
        "\n",
        "    try:\n",
        "        for epoch in range(start_epoch, config.epochs + 1):\n",
        "            print(f\"\\n{'='*80}\")\n",
        "            print(f\"EPOCH {epoch}/{config.epochs}\")\n",
        "            print(f\"{'='*80}\")\n",
        "\n",
        "            # Train\n",
        "            train_loss, train_acc = train_one_epoch(\n",
        "                model, train_loader, optimizer, scheduler, scaler, epoch, config\n",
        "            )\n",
        "\n",
        "            # Validate\n",
        "            val_loss, val_acc = validate(model, val_loader, config.device)\n",
        "\n",
        "            # Update history\n",
        "            history['train_loss'].append(train_loss)\n",
        "            history['train_acc'].append(train_acc)\n",
        "            history['val_loss'].append(val_loss)\n",
        "            history['val_acc'].append(val_acc)\n",
        "            history['learning_rates'].append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "            # Print summary\n",
        "            print(f\"\\n{'='*80}\")\n",
        "            print(f\"üìä Epoch {epoch} Summary:\")\n",
        "            print(f\"{'='*80}\")\n",
        "            print(f\"Train: Loss={train_loss:.4f}, Acc={train_acc:.2f}%\")\n",
        "            print(f\"Val:   Loss={val_loss:.4f}, Acc={val_acc:.2f}%\")\n",
        "            print(f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "            print(f\"{'='*80}\\n\")\n",
        "\n",
        "            # Save checkpoint\n",
        "            is_best = val_acc > best_val_acc\n",
        "            if is_best:\n",
        "                best_val_acc = val_acc\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            save_checkpoint(model, optimizer, scheduler, epoch, val_acc,\n",
        "                          history, config, label_names, is_best)\n",
        "\n",
        "            # Plot progress\n",
        "            if epoch % 5 == 0 or is_best:\n",
        "                plot_training_curves(history, config.plot_path)\n",
        "\n",
        "            # Early stopping\n",
        "            if patience_counter >= config.patience:\n",
        "                print(f\"‚ö†Ô∏è Early stopping at epoch {epoch}\")\n",
        "                break\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n‚ö†Ô∏è Training interrupted by user\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Error: {e}\")\n",
        "        print(\"üíæ Checkpoint saved - can resume later\")\n",
        "    finally:\n",
        "        # Final save\n",
        "        if 'val_acc' not in locals():\n",
        "            val_acc = best_val_acc\n",
        "\n",
        "        save_checkpoint(model, optimizer, scheduler, epoch, val_acc,\n",
        "                       history, config, label_names, False)\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"‚úÖ Training completed in {total_time/3600:.2f} hours\")\n",
        "    print(f\"‚úÖ Best accuracy: {best_val_acc:.2f}%\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    plot_training_curves(history, config.plot_path)\n",
        "\n",
        "    return model, history, label_names\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_8G0cjRc42d",
        "outputId": "f32b7ca7-e225-417d-828f-1e7d06e49437"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Evaluation and visualization functions loaded!\n",
            "üí° After training completes, run: evaluate_and_visualize()\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CELL: Complete Evaluation with All Presentation Visuals\n",
        "# ============================================================\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (confusion_matrix, classification_report,\n",
        "                            roc_curve, auc, precision_recall_curve)\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def evaluate_and_visualize():\n",
        "    \"\"\"Generate all visualizations for presentation\"\"\"\n",
        "\n",
        "    config = Config()\n",
        "\n",
        "    # Load best model\n",
        "    print(\"üîç Loading best trained model...\")\n",
        "    checkpoint = torch.load(config.best_ckpt_path, map_location=config.device)\n",
        "\n",
        "    # Get label names\n",
        "    train_df = pd.read_csv(config.train_csv)\n",
        "    label_names = sorted(train_df['label'].unique())\n",
        "    num_classes = len(label_names)\n",
        "\n",
        "    # Recreate model\n",
        "    model = MedicalAdaptiveViT(\n",
        "        img_size=config.img_size,\n",
        "        patch_size=config.patch_size,\n",
        "        num_classes=num_classes,\n",
        "        embed_dim=config.embed_dim,\n",
        "        depth=config.depth,\n",
        "        num_heads=config.num_heads,\n",
        "        mlp_ratio=config.mlp_ratio,\n",
        "        drop_rate=config.drop_rate,\n",
        "        drop_path_rate=config.drop_path_rate,\n",
        "        use_pathoscale=config.use_pathoscale,\n",
        "        pathoscale_kernel_sizes=config.pathoscale_kernel_sizes,\n",
        "        pathoscale_num_heads=config.pathoscale_num_heads,\n",
        "        medical_prior=config.medical_prior,\n",
        "        cross_scale_fusion=config.cross_scale_fusion,\n",
        "        pathology_guided=config.pathology_guided\n",
        "    ).to(config.device)\n",
        "\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "\n",
        "    # Load test data\n",
        "    # Use SimpleMedicalImagePreprocessor to get transforms\n",
        "    preprocessor = SimpleMedicalImagePreprocessor(img_size=config.img_size)\n",
        "    val_transform = preprocessor.get_val_transforms()\n",
        "\n",
        "    val_dataset = CustomImageDataset(config.test_csv, transform=val_transform)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=config.batch_size,\n",
        "                           shuffle=False, num_workers=config.num_workers)\n",
        "\n",
        "    # Get predictions\n",
        "    print(\"üìä Generating predictions...\")\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            # Skip batch if collate_fn returned None\n",
        "            if images is None:\n",
        "                continue\n",
        "            images = images.to(config.device)\n",
        "            logits, _, _ = model(images)\n",
        "            probs = F.softmax(logits, dim=1)\n",
        "            preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_probs = np.array(all_probs)\n",
        "\n",
        "    # Create results directory\n",
        "    os.makedirs(config.results_dir, exist_ok=True)\n",
        "\n",
        "    print(\"\\nüé® Generating visualizations...\\n\")\n",
        "\n",
        "    # 1. Confusion Matrix\n",
        "    print(\"1Ô∏è‚É£ Creating confusion matrix...\")\n",
        "    plot_confusion_matrix_pretty(all_labels, all_preds, label_names,\n",
        "                                 f\"{config.results_dir}/confusion_matrix.png\")\n",
        "\n",
        "    # 2. Per-class metrics\n",
        "    print(\"2Ô∏è‚É£ Creating per-class accuracy...\")\n",
        "    plot_per_class_metrics(all_labels, all_preds, label_names,\n",
        "                           f\"{config.results_dir}/per_class_accuracy.png\")\n",
        "\n",
        "    # 3. Classification report\n",
        "    print(\"3Ô∏è‚É£ Saving classification report...\")\n",
        "    save_classification_report(all_labels, all_preds, label_names,\n",
        "                               f\"{config.results_dir}/classification_report.txt\")\n",
        "\n",
        "    # 4. ROC curves\n",
        "    print(\"4Ô∏è‚É£ Creating ROC curves...\")\n",
        "    plot_roc_curves_multiclass(all_labels, all_probs, label_names,\n",
        "                               f\"{config.results_dir}/roc_curves.png\")\n",
        "\n",
        "    # 5. Top-k accuracy\n",
        "    print(\"5Ô∏è‚É£ Creating top-k accuracy...\")\n",
        "    plot_topk_accuracy(all_labels, all_probs,\n",
        "                      f\"{config.results_dir}/topk_accuracy.png\")\n",
        "\n",
        "    # 6. Confidence distribution\n",
        "    print(\"6Ô∏è‚É£ Creating confidence distribution...\")\n",
        "    plot_confidence_analysis(all_probs, all_preds, all_labels,\n",
        "                            f\"{config.results_dir}/confidence_distribution.png\")\n",
        "\n",
        "    # 7. Sample predictions\n",
        "    print(\"7Ô∏è‚É£ Creating sample predictions...\")\n",
        "    plot_sample_predictions(model, val_dataset, config.device, label_names,\n",
        "                           f\"{config.results_dir}/sample_predictions.png\")\n",
        "\n",
        "    # 8. Training history (if available)\n",
        "    if 'history' in checkpoint:\n",
        "        print(\"8Ô∏è‚É£ Creating training history plots...\")\n",
        "        plot_detailed_history(checkpoint['history'],\n",
        "                             f\"{config.results_dir}/training_history.png\")\n",
        "\n",
        "    # Calculate overall metrics\n",
        "    accuracy = (all_preds == all_labels).mean() * 100\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"üìà FINAL TEST RESULTS\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"Overall Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Total Samples: {len(all_labels):,}\")\n",
        "    print(f\"Number of Classes: {num_classes}\")\n",
        "    print(f\"Best Validation Accuracy: {checkpoint['val_acc']:.2f}%\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    print(\"‚úÖ All visualizations saved to:\", config.results_dir)\n",
        "    print(\"\\nGenerated files:\")\n",
        "    print(\"  1. confusion_matrix.png\")\n",
        "    print(\"  2. per_class_accuracy.png\")\n",
        "    print(\"  3. classification_report.txt\")\n",
        "    print(\"  4. roc_curves.png\")\n",
        "    print(\"  5. topk_accuracy.png\")\n",
        "    print(\"  6. confidence_distribution.png\")\n",
        "    print(\"  7. sample_predictions.png\")\n",
        "    print(\"  8. training_history.png\")\n",
        "    print(\"  9. training_curves.png (saved during training)\")\n",
        "\n",
        "    return all_preds, all_labels, all_probs\n",
        "\n",
        "def evaluate_and_visualize_comprehensive():\n",
        "    \"\"\"Enhanced evaluation with all metrics\"\"\"\n",
        "\n",
        "    # ... [Keep your existing setup code] ...\n",
        "\n",
        "    # Get predictions (same as before)\n",
        "    all_preds, all_labels, all_probs = get_predictions(model, val_loader, config.device)\n",
        "\n",
        "    print(\"\\nüé® Generating comprehensive visualizations...\\n\")\n",
        "\n",
        "    # Original visualizations\n",
        "    print(\"1Ô∏è‚É£ Creating confusion matrix...\")\n",
        "    plot_confusion_matrix_pretty(all_labels, all_preds, label_names,\n",
        "                                f\"{config.results_dir}/confusion_matrix.png\")\n",
        "\n",
        "    print(\"2Ô∏è‚É£ Creating per-class accuracy...\")\n",
        "    plot_per_class_metrics(all_labels, all_preds, label_names,\n",
        "                          f\"{config.results_dir}/per_class_accuracy.png\")\n",
        "\n",
        "    # NEW VISUALIZATIONS\n",
        "    print(\"3Ô∏è‚É£ Creating F1/Precision/Recall breakdown...\")\n",
        "    plot_f1_scores_per_class(all_labels, all_preds, label_names,\n",
        "                            f\"{config.results_dir}/f1_precision_recall.png\")\n",
        "\n",
        "    print(\"4Ô∏è‚É£ Creating macro/micro/weighted comparison...\")\n",
        "    plot_macro_micro_weighted_metrics(all_labels, all_preds, all_probs,\n",
        "                                     f\"{config.results_dir}/averaging_strategies.png\")\n",
        "\n",
        "    print(\"5Ô∏è‚É£ Creating Precision-Recall curves...\")\n",
        "    plot_precision_recall_curves(all_labels, all_probs, label_names,\n",
        "                                f\"{config.results_dir}/precision_recall_curves.png\")\n",
        "\n",
        "    print(\"6Ô∏è‚É£ Creating calibration analysis...\")\n",
        "    plot_calibration_curve(all_labels, all_probs,\n",
        "                          f\"{config.results_dir}/calibration_curve.png\")\n",
        "\n",
        "    print(\"7Ô∏è‚É£ Creating class imbalance analysis...\")\n",
        "    plot_class_imbalance_analysis(all_labels, all_preds, label_names,\n",
        "                                  f\"{config.results_dir}/class_imbalance_analysis.png\")\n",
        "\n",
        "    print(\"8Ô∏è‚É£ Creating misclassification heatmap...\")\n",
        "    plot_misclassification_matrix(all_labels, all_preds, label_names,\n",
        "                                  f\"{config.results_dir}/misclassification_heatmap.png\")\n",
        "\n",
        "    print(\"9Ô∏è‚É£ Creating MCC and balanced metrics...\")\n",
        "    plot_matthews_correlation_coefficient(all_labels, all_preds,\n",
        "                                         f\"{config.results_dir}/mcc_balanced_metrics.png\")\n",
        "\n",
        "    # ... [Keep your existing visualizations: ROC, top-k, confidence, samples, history] ...\n",
        "\n",
        "    print(\"\\n‚úÖ All visualizations complete!\")\n",
        "\n",
        "# Helper visualization functions\n",
        "def plot_confusion_matrix_pretty(y_true, y_pred, class_names, save_path):\n",
        "    \"\"\"Beautiful confusion matrix visualization\"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(22, 9))\n",
        "\n",
        "    # Raw counts\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
        "                xticklabels=class_names, yticklabels=class_names,\n",
        "                cbar_kws={'label': 'Count'}, linewidths=0.5)\n",
        "    axes[0].set_title('Confusion Matrix - Raw Counts', fontsize=16, fontweight='bold', pad=20)\n",
        "    axes[0].set_xlabel('Predicted Label', fontsize=13, fontweight='bold')\n",
        "    axes[0].set_ylabel('True Label', fontsize=13, fontweight='bold')\n",
        "    plt.setp(axes[0].get_xticklabels(), rotation=45, ha='right', fontsize=9)\n",
        "    plt.setp(axes[0].get_yticklabels(), rotation=0, fontsize=9)\n",
        "\n",
        "    # Normalized\n",
        "    sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='Greens', ax=axes[1],\n",
        "                xticklabels=class_names, yticklabels=class_names,\n",
        "                cbar_kws={'label': 'Proportion'}, linewidths=0.5)\n",
        "    axes[1].set_title('Confusion Matrix - Normalized', fontsize=16, fontweight='bold', pad=20)\n",
        "    axes[1].set_xlabel('Predicted Label', fontsize=13, fontweight='bold')\n",
        "    axes[1].set_ylabel('True Label', fontsize=13, fontweight='bold')\n",
        "    plt.setp(axes[1].get_xticklabels(), rotation=45, ha='right', fontsize=9)\n",
        "    plt.setp(axes[1].get_yticklabels(), rotation=0, fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_per_class_metrics(y_true, y_pred, class_names, save_path):\n",
        "    \"\"\"Per-class accuracy with color coding\"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
        "\n",
        "    # Sort by accuracy\n",
        "    sorted_idx = np.argsort(per_class_acc)\n",
        "    sorted_names = [class_names[i] for i in sorted_idx]\n",
        "    sorted_acc = per_class_acc[sorted_idx]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, max(10, len(class_names) * 0.45)))\n",
        "    colors = plt.cm.RdYlGn(sorted_acc)\n",
        "\n",
        "    bars = ax.barh(range(len(sorted_names)), sorted_acc * 100,\n",
        "                   color=colors, edgecolor='black', linewidth=1.2)\n",
        "    ax.set_yticks(range(len(sorted_names)))\n",
        "    ax.set_yticklabels(sorted_names, fontsize=10)\n",
        "    ax.set_xlabel('Accuracy (%)', fontsize=14, fontweight='bold')\n",
        "    ax.set_title('Per-Class Accuracy', fontsize=16, fontweight='bold', pad=20)\n",
        "    ax.set_xlim(0, 100)\n",
        "    ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
        "\n",
        "    # Add percentage labels\n",
        "    for i, (bar, acc) in enumerate(zip(bars, sorted_acc)):\n",
        "        ax.text(acc * 100 + 1.5, i, f'{acc*100:.1f}%',\n",
        "               va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def save_classification_report(y_true, y_pred, class_names, save_path):\n",
        "    \"\"\"Detailed classification report\"\"\"\n",
        "    report = classification_report(y_true, y_pred,\n",
        "                                   target_names=class_names, digits=4)\n",
        "\n",
        "    with open(save_path, 'w') as f:\n",
        "        f.write(\"=\"*100 + \"\\n\")\n",
        "        f.write(\"DETAILED CLASSIFICATION REPORT\\n\")\n",
        "        f.write(\"=\"*100 + \"\\n\\n\")\n",
        "        f.write(report)\n",
        "        f.write(\"\\n\" + \"=\"*100 + \"\\n\")\n",
        "\n",
        "\n",
        "def plot_roc_curves_multiclass(y_true, y_probs, class_names, save_path, max_classes=10):\n",
        "    \"\"\"ROC curves for top classes\"\"\"\n",
        "    n_classes = len(class_names)\n",
        "    y_true_bin = label_binarize(y_true, classes=range(n_classes))\n",
        "\n",
        "    # Select top classes\n",
        "    class_counts = np.bincount(y_true)\n",
        "    top_classes = np.argsort(class_counts)[-max_classes:]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 9))\n",
        "\n",
        "    colors = plt.cm.tab10(np.linspace(0, 1, max_classes))\n",
        "\n",
        "    for idx, i in enumerate(top_classes):\n",
        "        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_probs[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        ax.plot(fpr, tpr, lw=2.5, color=colors[idx],\n",
        "               label=f'{class_names[i][:25]} (AUC={roc_auc:.3f})')\n",
        "\n",
        "    ax.plot([0, 1], [0, 1], 'k--', lw=2, label='Random (AUC=0.5)')\n",
        "    ax.set_xlim([0.0, 1.0])\n",
        "    ax.set_ylim([0.0, 1.05])\n",
        "    ax.set_xlabel('False Positive Rate', fontsize=13, fontweight='bold')\n",
        "    ax.set_ylabel('True Positive Rate', fontsize=13, fontweight='bold')\n",
        "    ax.set_title(f'ROC Curves - Top {max_classes} Classes',\n",
        "                fontsize=16, fontweight='bold', pad=20)\n",
        "    ax.legend(loc='lower right', fontsize=9, framealpha=0.9)\n",
        "    ax.grid(alpha=0.3, linestyle='--')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_topk_accuracy(y_true, y_probs, save_path):\n",
        "    \"\"\"Top-k accuracy visualization\"\"\"\n",
        "    k_values = [1, 3, 5, 10]\n",
        "    accuracies = []\n",
        "\n",
        "    for k in k_values:\n",
        "        if k > y_probs.shape[1]:\n",
        "            k = y_probs.shape[1]\n",
        "        top_k_preds = np.argsort(y_probs, axis=1)[:, -k:]\n",
        "        correct = np.any(top_k_preds == y_true[:, None], axis=1)\n",
        "        acc = correct.mean() * 100\n",
        "        accuracies.append(acc)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 7))\n",
        "    colors = ['#3498db', '#2ecc71', '#f39c12', '#e74c3c']\n",
        "    bars = ax.bar([f'Top-{k}' for k in k_values], accuracies,\n",
        "                  color=colors, edgecolor='black', linewidth=1.5, width=0.6)\n",
        "\n",
        "    for bar, acc in zip(bars, accuracies):\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
        "                f'{acc:.2f}%', ha='center', va='bottom',\n",
        "                fontsize=14, fontweight='bold')\n",
        "\n",
        "    ax.set_ylabel('Accuracy (%)', fontsize=13, fontweight='bold')\n",
        "    ax.set_title('Top-K Accuracy', fontsize=16, fontweight='bold', pad=20)\n",
        "    ax.set_ylim(0, 105)\n",
        "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_confidence_analysis(y_probs, y_preds, y_true, save_path):\n",
        "    \"\"\"Prediction confidence analysis\"\"\"\n",
        "    max_probs = np.max(y_probs, axis=1)\n",
        "    correct = (y_preds == y_true)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "    # Histogram\n",
        "    axes[0].hist(max_probs[correct], bins=40, alpha=0.7,\n",
        "                label='Correct', color='green', edgecolor='black')\n",
        "    axes[0].hist(max_probs[~correct], bins=40, alpha=0.7,\n",
        "                label='Incorrect', color='red', edgecolor='black')\n",
        "    axes[0].set_xlabel('Prediction Confidence', fontsize=12, fontweight='bold')\n",
        "    axes[0].set_ylabel('Count', fontsize=12, fontweight='bold')\n",
        "    axes[0].set_title('Confidence Distribution', fontsize=14, fontweight='bold')\n",
        "    axes[0].legend(fontsize=11)\n",
        "    axes[0].grid(alpha=0.3)\n",
        "\n",
        "    # Box plot\n",
        "    data = [max_probs[correct], max_probs[~correct]]\n",
        "    box = axes[1].boxplot(data, labels=['Correct', 'Incorrect'],\n",
        "                         patch_artist=True, widths=0.5)\n",
        "    box['boxes'][0].set_facecolor('lightgreen')\n",
        "    box['boxes'][1].set_facecolor('lightcoral')\n",
        "    axes[1].set_ylabel('Prediction Confidence', fontsize=12, fontweight='bold')\n",
        "    axes[1].set_title('Confidence by Correctness', fontsize=14, fontweight='bold')\n",
        "    axes[1].grid(alpha=0.3, axis='y')\n",
        "\n",
        "    # Confidence bins\n",
        "    bins = [0, 0.5, 0.7, 0.8, 0.9, 1.0]\n",
        "    bin_labels = ['0-50%', '50-70%', '70-80%', '80-90%', '90-100%']\n",
        "    correct_counts = []\n",
        "    total_counts = []\n",
        "\n",
        "    for i in range(len(bins)-1):\n",
        "        mask = (max_probs >= bins[i]) & (max_probs < bins[i+1])\n",
        "        if i == len(bins)-2:  # Include 1.0 in last bin\n",
        "            mask = (max_probs >= bins[i]) & (max_probs <= bins[i+1])\n",
        "        correct_counts.append(correct[mask].sum())\n",
        "        total_counts.append(mask.sum())\n",
        "\n",
        "    accuracies = [c/t*100 if t > 0 else 0 for c, t in zip(correct_counts, total_counts)]\n",
        "\n",
        "    axes[2].bar(bin_labels, accuracies, color='skyblue', edgecolor='black', linewidth=1.5)\n",
        "    axes[2].set_xlabel('Confidence Range', fontsize=12, fontweight='bold')\n",
        "    axes[2].set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
        "    axes[2].set_title('Accuracy by Confidence Range', fontsize=14, fontweight='bold')\n",
        "    axes[2].grid(alpha=0.3, axis='y')\n",
        "\n",
        "    for i, (acc, count) in enumerate(zip(accuracies, total_counts)):\n",
        "        axes[2].text(i, acc + 2, f'{acc:.1f}%\\n(n={count})',\n",
        "                    ha='center', fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_sample_predictions(model, dataset, device, label_names, save_path, num_samples=16):\n",
        "    \"\"\"Visualize sample predictions\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    indices = np.random.choice(len(dataset), min(num_samples, len(dataset)), replace=False)\n",
        "\n",
        "    fig, axes = plt.subplots(4, 4, figsize=(18, 18))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for idx, sample_idx in enumerate(indices):\n",
        "        image, true_label = dataset[sample_idx]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            image_batch = image.unsqueeze(0).to(device)\n",
        "            logits, _, _ = model(image_batch)\n",
        "            probs = F.softmax(logits, dim=1)\n",
        "            pred_label = torch.argmax(probs).item()\n",
        "            confidence = probs[0, pred_label].item()\n",
        "\n",
        "        # Denormalize\n",
        "        img_display = image.cpu().numpy().transpose(1, 2, 0)\n",
        "        img_display = img_display * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "        img_display = np.clip(img_display, 0, 1)\n",
        "\n",
        "        axes[idx].imshow(img_display)\n",
        "        axes[idx].axis('off')\n",
        "\n",
        "        color = 'green' if pred_label == true_label else 'red'\n",
        "        true_name = label_names[true_label][:22]\n",
        "        pred_name = label_names[pred_label][:22]\n",
        "\n",
        "        title = f\"True: {true_name}\\nPred: {pred_name}\\nConf: {confidence:.2%}\"\n",
        "        axes[idx].set_title(title, fontsize=10, color=color, fontweight='bold', pad=10)\n",
        "\n",
        "    plt.suptitle('Sample Predictions (Green=Correct, Red=Incorrect)',\n",
        "                fontsize=16, fontweight='bold', y=0.995)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_detailed_history(history, save_path):\n",
        "    \"\"\"Detailed training history plots\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "    epochs = range(1, len(history['train_loss']) + 1)\n",
        "\n",
        "    # Loss curves\n",
        "    axes[0, 0].plot(epochs, history['train_loss'], 'b-o', label='Train Loss', linewidth=2)\n",
        "    axes[0, 0].plot(epochs, history['val_loss'], 'r-s', label='Val Loss', linewidth=2)\n",
        "    axes[0, 0].set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "    axes[0, 0].set_ylabel('Loss', fontsize=12, fontweight='bold')\n",
        "    axes[0, 0].set_title('Training & Validation Loss', fontsize=14, fontweight='bold')\n",
        "    axes[0, 0].legend(fontsize=11)\n",
        "    axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "    # Accuracy curves\n",
        "    axes[0, 1].plot(epochs, history['train_acc'], 'b-o', label='Train Acc', linewidth=2)\n",
        "    axes[0, 1].plot(epochs, history['val_acc'], 'r-s', label='Val Acc', linewidth=2)\n",
        "    axes[0, 1].set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "    axes[0, 1].set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
        "    axes[0, 1].set_title('Training & Validation Accuracy', fontsize=14, fontweight='bold')\n",
        "    axes[0, 1].legend(fontsize=11)\n",
        "    axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "    # Learning rate\n",
        "    axes[1, 0].plot(epochs, history['learning_rates'], 'g-', linewidth=2)\n",
        "    axes[1, 0].set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "    axes[1, 0].set_ylabel('Learning Rate', fontsize=12, fontweight='bold')\n",
        "    axes[1, 0].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
        "    axes[1, 0].set_yscale('log')\n",
        "    axes[1, 0].grid(alpha=0.3)\n",
        "\n",
        "    # Overfitting analysis\n",
        "    gap = np.array(history['train_acc']) - np.array(history['val_acc'])\n",
        "    axes[1, 1].plot(epochs, gap, 'm-', linewidth=2)\n",
        "    axes[1, 1].axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
        "    axes[1, 1].set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "    axes[1, 1].set_ylabel('Accuracy Gap (%)', fontsize=12, fontweight='bold')\n",
        "    axes[1, 1].set_title('Train-Val Accuracy Gap (Overfitting Indicator)',\n",
        "                        fontsize=14, fontweight='bold')\n",
        "    axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "print(\"‚úÖ Evaluation and visualization functions loaded!\")\n",
        "print(\"üí° After training completes, run: evaluate_and_visualize()\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib8-2OA_A8fw",
        "outputId": "ebe70522-ce60-4160-c601-116077400f92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "üöÄ RESUMING TRAINING\n",
            "================================================================================\n",
            "‚úÖ GPU is available! Using device: cuda\n",
            "GPU Name: Tesla T4\n",
            "GPU Memory: 15.83 GB\n",
            "\n",
            "üìä Classes: 22, Train: 33,531, Test: 8,383\n",
            "\n",
            "üèóÔ∏è Building model...\n",
            "‚úÖ Parameters: 20.10M\n",
            "\n",
            "‚úÖ Found checkpoint: /content/drive/MyDrive/SkinDiseaseProject/checkpoints/latest_checkpoint.pth\n",
            "üîÑ Resuming training...\n",
            "‚úÖ Resumed from epoch 8\n",
            "üìä Best accuracy so far: 49.59%\n",
            "\n",
            "üöÄ Starting training...\n",
            "\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "EPOCH 9/50\n",
            "================================================================================\n",
            "  Epoch [9/50] Batch [300/1397] Loss: 1.6873 Acc: 48.53% LR: 0.000061\n",
            "  Epoch [9/50] Batch [600/1397] Loss: 1.6926 Acc: 48.35% LR: 0.000072\n",
            "  Epoch [9/50] Batch [900/1397] Loss: 1.7027 Acc: 48.03% LR: 0.000082\n",
            "  Epoch [9/50] Batch [1200/1397] Loss: 1.7045 Acc: 47.96% LR: 0.000093\n",
            "\n",
            "================================================================================\n",
            "üìä Epoch 9 Summary:\n",
            "================================================================================\n",
            "Train: Loss=1.7072, Acc=47.84%\n",
            "Val:   Loss=1.6688, Acc=49.45%\n",
            "LR: 0.000100\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "EPOCH 10/50\n",
            "================================================================================\n",
            "  Epoch [10/50] Batch [300/1397] Loss: 1.7019 Acc: 48.10% LR: 0.000111\n",
            "  Epoch [10/50] Batch [600/1397] Loss: 1.7099 Acc: 47.79% LR: 0.000122\n",
            "  Epoch [10/50] Batch [900/1397] Loss: 1.7146 Acc: 47.74% LR: 0.000132\n",
            "  Epoch [10/50] Batch [1200/1397] Loss: 1.7192 Acc: 47.47% LR: 0.000143\n",
            "\n",
            "================================================================================\n",
            "üìä Epoch 10 Summary:\n",
            "================================================================================\n",
            "Train: Loss=1.7269, Acc=47.18%\n",
            "Val:   Loss=1.6844, Acc=48.97%\n",
            "LR: 0.000150\n",
            "================================================================================\n",
            "\n",
            "üíæ Checkpoint saved: epoch_10.pth\n",
            "‚úÖ Curves saved: /content/drive/MyDrive/SkinDiseaseProject/training_curves.png\n",
            "\n",
            "================================================================================\n",
            "EPOCH 11/50\n",
            "================================================================================\n",
            "  Epoch [11/50] Batch [300/1397] Loss: 1.7128 Acc: 47.21% LR: 0.000139\n",
            "  Epoch [11/50] Batch [600/1397] Loss: 1.7226 Acc: 47.17% LR: 0.000128\n",
            "  Epoch [11/50] Batch [900/1397] Loss: 1.7171 Acc: 47.51% LR: 0.000118\n",
            "  Epoch [11/50] Batch [1200/1397] Loss: 1.7028 Acc: 47.83% LR: 0.000107\n",
            "\n",
            "================================================================================\n",
            "üìä Epoch 11 Summary:\n",
            "================================================================================\n",
            "Train: Loss=1.6939, Acc=48.05%\n",
            "Val:   Loss=1.6136, Acc=51.57%\n",
            "LR: 0.000100\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Best model saved: 51.57%\n",
            "‚úÖ Curves saved: /content/drive/MyDrive/SkinDiseaseProject/training_curves.png\n",
            "\n",
            "================================================================================\n",
            "EPOCH 12/50\n",
            "================================================================================\n",
            "  Epoch [12/50] Batch [300/1397] Loss: 1.6291 Acc: 49.68% LR: 0.000089\n",
            "  Epoch [12/50] Batch [600/1397] Loss: 1.6194 Acc: 50.05% LR: 0.000078\n",
            "  Epoch [12/50] Batch [900/1397] Loss: 1.6094 Acc: 50.52% LR: 0.000068\n",
            "  Epoch [12/50] Batch [1200/1397] Loss: 1.6081 Acc: 50.53% LR: 0.000057\n",
            "\n",
            "================================================================================\n",
            "üìä Epoch 12 Summary:\n",
            "================================================================================\n",
            "Train: Loss=1.6029, Acc=50.85%\n",
            "Val:   Loss=1.5522, Acc=53.19%\n",
            "LR: 0.000050\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Best model saved: 53.19%\n",
            "‚úÖ Curves saved: /content/drive/MyDrive/SkinDiseaseProject/training_curves.png\n",
            "\n",
            "================================================================================\n",
            "EPOCH 13/50\n",
            "================================================================================\n",
            "  Epoch [13/50] Batch [300/1397] Loss: 1.5545 Acc: 52.54% LR: 0.000061\n",
            "  Epoch [13/50] Batch [600/1397] Loss: 1.5499 Acc: 52.59% LR: 0.000072\n",
            "  Epoch [13/50] Batch [900/1397] Loss: 1.5511 Acc: 52.55% LR: 0.000082\n",
            "  Epoch [13/50] Batch [1200/1397] Loss: 1.5615 Acc: 52.08% LR: 0.000093\n",
            "\n",
            "================================================================================\n",
            "üìä Epoch 13 Summary:\n",
            "================================================================================\n",
            "Train: Loss=1.5672, Acc=52.03%\n",
            "Val:   Loss=1.5503, Acc=52.90%\n",
            "LR: 0.000100\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "EPOCH 14/50\n",
            "================================================================================\n",
            "  Epoch [14/50] Batch [300/1397] Loss: 1.5956 Acc: 51.01% LR: 0.000111\n",
            "  Epoch [14/50] Batch [600/1397] Loss: 1.5946 Acc: 50.86% LR: 0.000122\n",
            "  Epoch [14/50] Batch [900/1397] Loss: 1.5863 Acc: 51.06% LR: 0.000132\n",
            "  Epoch [14/50] Batch [1200/1397] Loss: 1.5874 Acc: 51.01% LR: 0.000143\n",
            "\n",
            "================================================================================\n",
            "üìä Epoch 14 Summary:\n",
            "================================================================================\n",
            "Train: Loss=1.5942, Acc=50.83%\n",
            "Val:   Loss=1.5516, Acc=52.87%\n",
            "LR: 0.000150\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "EPOCH 15/50\n",
            "================================================================================\n",
            "  Epoch [15/50] Batch [300/1397] Loss: 1.5652 Acc: 51.96% LR: 0.000139\n",
            "  Epoch [15/50] Batch [600/1397] Loss: 1.5746 Acc: 51.64% LR: 0.000128\n",
            "  Epoch [15/50] Batch [900/1397] Loss: 1.5817 Acc: 51.34% LR: 0.000118\n",
            "  Epoch [15/50] Batch [1200/1397] Loss: 1.5789 Acc: 51.47% LR: 0.000107\n",
            "\n",
            "================================================================================\n",
            "üìä Epoch 15 Summary:\n",
            "================================================================================\n",
            "Train: Loss=1.5720, Acc=51.71%\n",
            "Val:   Loss=1.5259, Acc=53.86%\n",
            "LR: 0.000100\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Best model saved: 53.86%\n",
            "üíæ Checkpoint saved: epoch_15.pth\n",
            "‚úÖ Curves saved: /content/drive/MyDrive/SkinDiseaseProject/training_curves.png\n",
            "\n",
            "================================================================================\n",
            "EPOCH 16/50\n",
            "================================================================================\n",
            "  Epoch [16/50] Batch [300/1397] Loss: 1.5052 Acc: 52.76% LR: 0.000089\n",
            "  Epoch [16/50] Batch [600/1397] Loss: 1.4950 Acc: 53.72% LR: 0.000078\n",
            "  Epoch [16/50] Batch [900/1397] Loss: 1.4966 Acc: 53.88% LR: 0.000068\n",
            "  Epoch [16/50] Batch [1200/1397] Loss: 1.4880 Acc: 54.14% LR: 0.000057\n",
            "\n",
            "================================================================================\n",
            "üìä Epoch 16 Summary:\n",
            "================================================================================\n",
            "Train: Loss=1.4857, Acc=54.25%\n",
            "Val:   Loss=1.4357, Acc=56.87%\n",
            "LR: 0.000050\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Best model saved: 56.87%\n",
            "‚úÖ Curves saved: /content/drive/MyDrive/SkinDiseaseProject/training_curves.png\n",
            "\n",
            "================================================================================\n",
            "EPOCH 17/50\n",
            "================================================================================\n",
            "  Epoch [17/50] Batch [300/1397] Loss: 1.4151 Acc: 56.14% LR: 0.000061\n",
            "  Epoch [17/50] Batch [600/1397] Loss: 1.4223 Acc: 55.90% LR: 0.000072\n",
            "  Epoch [17/50] Batch [900/1397] Loss: 1.4288 Acc: 55.55% LR: 0.000082\n",
            "  Epoch [17/50] Batch [1200/1397] Loss: 1.4330 Acc: 55.52% LR: 0.000093\n",
            "\n",
            "================================================================================\n",
            "üìä Epoch 17 Summary:\n",
            "================================================================================\n",
            "Train: Loss=1.4364, Acc=55.45%\n",
            "Val:   Loss=1.4577, Acc=55.67%\n",
            "LR: 0.000100\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "EPOCH 18/50\n",
            "================================================================================\n",
            "  Epoch [18/50] Batch [300/1397] Loss: 1.4232 Acc: 56.68% LR: 0.000111\n",
            "  Epoch [18/50] Batch [600/1397] Loss: 1.4449 Acc: 55.62% LR: 0.000122\n",
            "  Epoch [18/50] Batch [900/1397] Loss: 1.4558 Acc: 55.22% LR: 0.000132\n",
            "  Epoch [18/50] Batch [1200/1397] Loss: 1.4643 Acc: 54.93% LR: 0.000143\n",
            "\n",
            "================================================================================\n",
            "üìä Epoch 18 Summary:\n",
            "================================================================================\n",
            "Train: Loss=1.4690, Acc=54.66%\n",
            "Val:   Loss=1.5126, Acc=54.30%\n",
            "LR: 0.000150\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "EPOCH 19/50\n",
            "================================================================================\n",
            "  Epoch [19/50] Batch [300/1397] Loss: 1.4482 Acc: 55.54% LR: 0.000139\n",
            "  Epoch [19/50] Batch [600/1397] Loss: 1.4662 Acc: 54.69% LR: 0.000128\n",
            "  Epoch [19/50] Batch [900/1397] Loss: 1.4550 Acc: 55.07% LR: 0.000118\n",
            "  Epoch [19/50] Batch [1200/1397] Loss: 1.4613 Acc: 54.95% LR: 0.000107\n",
            "\n",
            "================================================================================\n",
            "üìä Epoch 19 Summary:\n",
            "================================================================================\n",
            "Train: Loss=1.4571, Acc=55.07%\n",
            "Val:   Loss=1.4428, Acc=56.88%\n",
            "LR: 0.000100\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Best model saved: 56.88%\n",
            "‚úÖ Curves saved: /content/drive/MyDrive/SkinDiseaseProject/training_curves.png\n",
            "\n",
            "================================================================================\n",
            "EPOCH 20/50\n",
            "================================================================================\n",
            "  Epoch [20/50] Batch [300/1397] Loss: 1.3786 Acc: 57.18% LR: 0.000089\n",
            "  Epoch [20/50] Batch [600/1397] Loss: 1.3767 Acc: 57.33% LR: 0.000078\n",
            "  Epoch [20/50] Batch [900/1397] Loss: 1.3642 Acc: 57.88% LR: 0.000068\n",
            "  Epoch [20/50] Batch [1200/1397] Loss: 1.3595 Acc: 57.99% LR: 0.000057\n",
            "\n",
            "================================================================================\n",
            "üìä Epoch 20 Summary:\n",
            "================================================================================\n",
            "Train: Loss=1.3566, Acc=57.98%\n",
            "Val:   Loss=1.4124, Acc=57.62%\n",
            "LR: 0.000050\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Best model saved: 57.62%\n",
            "üíæ Checkpoint saved: epoch_20.pth\n",
            "‚úÖ Curves saved: /content/drive/MyDrive/SkinDiseaseProject/training_curves.png\n",
            "\n",
            "================================================================================\n",
            "EPOCH 21/50\n",
            "================================================================================\n",
            "  Epoch [21/50] Batch [300/1397] Loss: 1.2895 Acc: 60.36% LR: 0.000061\n",
            "  Epoch [21/50] Batch [600/1397] Loss: 1.2774 Acc: 60.59% LR: 0.000072\n",
            "  Epoch [21/50] Batch [900/1397] Loss: 1.2925 Acc: 59.92% LR: 0.000082\n",
            "  Epoch [21/50] Batch [1200/1397] Loss: 1.3081 Acc: 59.61% LR: 0.000093\n",
            "\n",
            "================================================================================\n",
            "üìä Epoch 21 Summary:\n",
            "================================================================================\n",
            "Train: Loss=1.3109, Acc=59.57%\n",
            "Val:   Loss=1.4285, Acc=56.97%\n",
            "LR: 0.000100\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "EPOCH 22/50\n",
            "================================================================================\n",
            "  Epoch [22/50] Batch [300/1397] Loss: 1.3094 Acc: 59.94% LR: 0.000111\n",
            "  Epoch [22/50] Batch [600/1397] Loss: 1.3277 Acc: 59.18% LR: 0.000122\n",
            "  Epoch [22/50] Batch [900/1397] Loss: 1.3373 Acc: 58.66% LR: 0.000132\n",
            "  Epoch [22/50] Batch [1200/1397] Loss: 1.3524 Acc: 58.12% LR: 0.000143\n",
            "\n",
            "================================================================================\n",
            "üìä Epoch 22 Summary:\n",
            "================================================================================\n",
            "Train: Loss=1.3609, Acc=57.86%\n",
            "Val:   Loss=1.4490, Acc=56.14%\n",
            "LR: 0.000150\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "EPOCH 23/50\n",
            "================================================================================\n",
            "  Epoch [23/50] Batch [300/1397] Loss: 1.3747 Acc: 57.62% LR: 0.000139\n",
            "  Epoch [23/50] Batch [600/1397] Loss: 1.3597 Acc: 58.16% LR: 0.000128\n",
            "  Epoch [23/50] Batch [900/1397] Loss: 1.3562 Acc: 58.35% LR: 0.000118\n",
            "  Epoch [23/50] Batch [1200/1397] Loss: 1.3481 Acc: 58.50% LR: 0.000107\n",
            "\n",
            "================================================================================\n",
            "üìä Epoch 23 Summary:\n",
            "================================================================================\n",
            "Train: Loss=1.3462, Acc=58.52%\n",
            "Val:   Loss=1.3646, Acc=59.45%\n",
            "LR: 0.000100\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Best model saved: 59.45%\n",
            "‚úÖ Curves saved: /content/drive/MyDrive/SkinDiseaseProject/training_curves.png\n",
            "\n",
            "================================================================================\n",
            "EPOCH 24/50\n",
            "================================================================================\n",
            "  Epoch [24/50] Batch [300/1397] Loss: 1.2645 Acc: 60.62% LR: 0.000089\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# JUST RUN THIS - IT WILL AUTO-RESUME!\n",
        "# ============================================================\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"üöÄ RESUMING TRAINING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "result = main_training_continuous()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynntmdO5y78b",
        "outputId": "28c17b31-4ec5-4871-f7d2-bda7e860c4d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Loading best trained model...\n",
            "üìä Generating predictions...\n",
            "\n",
            "üé® Generating visualizations...\n",
            "\n",
            "1Ô∏è‚É£ Creating confusion matrix...\n",
            "2Ô∏è‚É£ Creating per-class accuracy...\n",
            "3Ô∏è‚É£ Saving classification report...\n",
            "4Ô∏è‚É£ Creating ROC curves...\n",
            "5Ô∏è‚É£ Creating top-k accuracy...\n",
            "6Ô∏è‚É£ Creating confidence distribution...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-617834808.py:319: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  box = axes[1].boxplot(data, labels=['Correct', 'Incorrect'],\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7Ô∏è‚É£ Creating sample predictions...\n",
            "8Ô∏è‚É£ Creating training history plots...\n",
            "\n",
            "================================================================================\n",
            "üìà FINAL TEST RESULTS\n",
            "================================================================================\n",
            "Overall Accuracy: 74.89%\n",
            "Total Samples: 8,383\n",
            "Number of Classes: 22\n",
            "Best Validation Accuracy: 74.89%\n",
            "================================================================================\n",
            "\n",
            "‚úÖ All visualizations saved to: /content/drive/MyDrive/SkinDiseaseProject/results\n",
            "\n",
            "Generated files:\n",
            "  1. confusion_matrix.png\n",
            "  2. per_class_accuracy.png\n",
            "  3. classification_report.txt\n",
            "  4. roc_curves.png\n",
            "  5. topk_accuracy.png\n",
            "  6. confidence_distribution.png\n",
            "  7. sample_predictions.png\n",
            "  8. training_history.png\n",
            "  9. training_curves.png (saved during training)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0, 10, 12, ..., 17,  5,  4]),\n",
              " array([ 0, 10, 12, ..., 17,  5, 11]),\n",
              " array([[9.99857783e-01, 1.54017471e-06, 4.05175088e-05, ...,\n",
              "         5.60537217e-07, 2.45184947e-06, 4.57607130e-05],\n",
              "        [1.00097841e-05, 3.88609209e-07, 1.65369420e-06, ...,\n",
              "         4.52972188e-07, 1.16377706e-07, 5.13406940e-06],\n",
              "        [9.03824039e-05, 5.58994303e-04, 6.23662127e-05, ...,\n",
              "         3.70370144e-05, 2.72501184e-05, 3.28606693e-05],\n",
              "        ...,\n",
              "        [5.91997057e-02, 1.77766255e-03, 1.51823973e-04, ...,\n",
              "         6.12493721e-04, 6.75037736e-05, 3.75010632e-02],\n",
              "        [5.74609487e-07, 1.30308422e-07, 4.02181115e-08, ...,\n",
              "         2.67205223e-07, 1.09924407e-08, 7.36031254e-08],\n",
              "        [2.50629466e-02, 4.05517220e-03, 3.92646855e-03, ...,\n",
              "         6.57733483e-03, 7.08894106e-03, 4.97573940e-03]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "evaluate_and_visualize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7HnJy6y8DP4",
        "outputId": "677f3c0c-b50c-4c63-9920-eeb51593a90a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "üîç CHECKING FOR SAVED CHECKPOINTS\n",
            "============================================================\n",
            "\n",
            "‚úÖ Found 11 file(s):\n",
            "   üìÅ best_checkpoint.pth (226.8 MB)\n",
            "   üìÅ epoch_10.pth (226.8 MB)\n",
            "   üìÅ epoch_15.pth (226.8 MB)\n",
            "   üìÅ epoch_20.pth (226.8 MB)\n",
            "   üìÅ epoch_25.pth (226.8 MB)\n",
            "   üìÅ epoch_30.pth (226.8 MB)\n",
            "   üìÅ epoch_35.pth (226.8 MB)\n",
            "   üìÅ epoch_40.pth (226.8 MB)\n",
            "   üìÅ epoch_45.pth (226.8 MB)\n",
            "   üìÅ epoch_50.pth (226.8 MB)\n",
            "   üìÅ latest_checkpoint.pth (226.8 MB)\n",
            "\n",
            "‚úÖ Best checkpoint found!\n",
            "   Epoch: 8\n",
            "   Accuracy: 49.59%\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CHECK FOR SAVED CHECKPOINTS\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "\n",
        "checkpoint_dir = '/content/drive/MyDrive/SkinDiseaseProject/checkpoints'\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üîç CHECKING FOR SAVED CHECKPOINTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if os.path.exists(checkpoint_dir):\n",
        "    files = os.listdir(checkpoint_dir)\n",
        "    if files:\n",
        "        print(f\"\\n‚úÖ Found {len(files)} file(s):\")\n",
        "        for f in files:\n",
        "            file_path = os.path.join(checkpoint_dir, f)\n",
        "            size_mb = os.path.getsize(file_path) / (1024*1024)\n",
        "            print(f\"   üìÅ {f} ({size_mb:.1f} MB)\")\n",
        "\n",
        "        # Check best checkpoint\n",
        "        best_ckpt = os.path.join(checkpoint_dir, 'best_checkpoint.pth')\n",
        "        if os.path.exists(best_ckpt):\n",
        "            import torch\n",
        "            ckpt = torch.load(best_ckpt, map_location='cpu')\n",
        "            print(f\"\\n‚úÖ Best checkpoint found!\")\n",
        "            print(f\"   Epoch: {ckpt.get('epoch', '?')}\")\n",
        "            print(f\"   Accuracy: {ckpt.get('val_acc', 0):.2f}%\")\n",
        "    else:\n",
        "        print(\"\\n‚ùå Checkpoint directory is empty\")\n",
        "else:\n",
        "    print(\"\\n‚ùå Checkpoint directory doesn't exist\")\n",
        "\n",
        "# Check for backups\n",
        "backup_dir = '/content/drive/MyDrive/SkinDiseaseProject/checkpoints_backup'\n",
        "if os.path.exists(backup_dir):\n",
        "    print(f\"\\n‚úÖ Found backup directory: {backup_dir}\")\n",
        "    backup_files = os.listdir(backup_dir)\n",
        "    print(f\"   Contains {len(backup_files)} file(s)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWqCVB8N8ULG",
        "outputId": "474fd233-a050-4f0d-c193-15c4fba0e671"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ GPU is available! Using device: cuda\n",
            "GPU Name: Tesla T4\n",
            "GPU Memory: 15.83 GB\n",
            "\n",
            "üìä Classes: 22, Train: 33,531, Test: 8,383\n",
            "\n",
            "üèóÔ∏è Building model...\n",
            "‚úÖ Parameters: 20.10M\n",
            "\n",
            "‚úÖ Found checkpoint: /content/drive/MyDrive/SkinDiseaseProject/checkpoints/latest_checkpoint.pth\n",
            "üîÑ Resuming training...\n",
            "‚úÖ Resumed from epoch 52\n",
            "üìä Best accuracy so far: 70.40%\n",
            "\n",
            "üöÄ Starting training...\n",
            "\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "EPOCH 53/67\n",
            "================================================================================\n",
            "  Epoch [53/67] Batch [300/1397] Loss: 0.6322 Acc: 78.53% LR: 0.000135\n",
            "  Epoch [53/67] Batch [600/1397] Loss: 0.6257 Acc: 78.41% LR: 0.000125\n",
            "  Epoch [53/67] Batch [900/1397] Loss: 0.6193 Acc: 78.83% LR: 0.000114\n",
            "  Epoch [53/67] Batch [1200/1397] Loss: 0.6180 Acc: 79.00% LR: 0.000103\n",
            "\n",
            "================================================================================\n",
            "üìä Epoch 53 Summary:\n",
            "================================================================================\n",
            "Train: Loss=0.6169, Acc=79.01%\n",
            "Val:   Loss=0.9984, Acc=72.98%\n",
            "LR: 0.000096\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Best model saved: 72.98%\n",
            "‚úÖ Curves saved: /content/drive/MyDrive/SkinDiseaseProject/training_curves.png\n",
            "\n",
            "================================================================================\n",
            "EPOCH 54/67\n",
            "================================================================================\n",
            "  Epoch [54/67] Batch [300/1397] Loss: 0.5137 Acc: 82.31% LR: 0.000085\n",
            "  Epoch [54/67] Batch [600/1397] Loss: 0.5116 Acc: 82.25% LR: 0.000075\n",
            "  Epoch [54/67] Batch [900/1397] Loss: 0.5064 Acc: 82.41% LR: 0.000064\n",
            "  Epoch [54/67] Batch [1200/1397] Loss: 0.5066 Acc: 82.40% LR: 0.000053\n",
            "\n",
            "================================================================================\n",
            "üìä Epoch 54 Summary:\n",
            "================================================================================\n",
            "Train: Loss=0.5013, Acc=82.54%\n",
            "Val:   Loss=0.9942, Acc=73.82%\n",
            "LR: 0.000054\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Best model saved: 73.82%\n",
            "‚úÖ Curves saved: /content/drive/MyDrive/SkinDiseaseProject/training_curves.png\n",
            "\n",
            "================================================================================\n",
            "EPOCH 55/67\n",
            "================================================================================\n",
            "  Epoch [55/67] Batch [300/1397] Loss: 0.4215 Acc: 85.32% LR: 0.000065\n",
            "  Epoch [55/67] Batch [600/1397] Loss: 0.4321 Acc: 84.82% LR: 0.000075\n",
            "  Epoch [55/67] Batch [900/1397] Loss: 0.4421 Acc: 84.50% LR: 0.000086\n",
            "  Epoch [55/67] Batch [1200/1397] Loss: 0.4603 Acc: 83.94% LR: 0.000097\n",
            "\n",
            "================================================================================\n",
            "üìä Epoch 55 Summary:\n",
            "================================================================================\n",
            "Train: Loss=0.4680, Acc=83.61%\n",
            "Val:   Loss=1.0431, Acc=73.05%\n",
            "LR: 0.000104\n",
            "================================================================================\n",
            "\n",
            "üíæ Checkpoint saved: epoch_55.pth\n",
            "‚úÖ Curves saved: /content/drive/MyDrive/SkinDiseaseProject/training_curves.png\n",
            "\n",
            "================================================================================\n",
            "EPOCH 56/67\n",
            "================================================================================\n",
            "  Epoch [56/67] Batch [300/1397] Loss: 0.4976 Acc: 82.78% LR: 0.000115\n",
            "  Epoch [56/67] Batch [600/1397] Loss: 0.5010 Acc: 82.65% LR: 0.000125\n",
            "  Epoch [56/67] Batch [900/1397] Loss: 0.5214 Acc: 81.79% LR: 0.000136\n",
            "  Epoch [56/67] Batch [1200/1397] Loss: 0.5428 Acc: 81.10% LR: 0.000147\n",
            "\n",
            "================================================================================\n",
            "üìä Epoch 56 Summary:\n",
            "================================================================================\n",
            "Train: Loss=0.5524, Acc=80.70%\n",
            "Val:   Loss=1.0849, Acc=71.24%\n",
            "LR: 0.000146\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "EPOCH 57/67\n",
            "================================================================================\n",
            "  Epoch [57/67] Batch [300/1397] Loss: 0.5423 Acc: 80.83% LR: 0.000135\n",
            "  Epoch [57/67] Batch [600/1397] Loss: 0.5399 Acc: 80.93% LR: 0.000125\n",
            "  Epoch [57/67] Batch [900/1397] Loss: 0.5408 Acc: 80.95% LR: 0.000114\n",
            "  Epoch [57/67] Batch [1200/1397] Loss: 0.5425 Acc: 81.07% LR: 0.000103\n",
            "\n",
            "================================================================================\n",
            "üìä Epoch 57 Summary:\n",
            "================================================================================\n",
            "Train: Loss=0.5423, Acc=81.06%\n",
            "Val:   Loss=1.0042, Acc=73.59%\n",
            "LR: 0.000096\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "EPOCH 58/67\n",
            "================================================================================\n",
            "  Epoch [58/67] Batch [300/1397] Loss: 0.4351 Acc: 84.79% LR: 0.000085\n",
            "  Epoch [58/67] Batch [600/1397] Loss: 0.4325 Acc: 84.75% LR: 0.000075\n",
            "  Epoch [58/67] Batch [900/1397] Loss: 0.4268 Acc: 84.82% LR: 0.000064\n",
            "  Epoch [58/67] Batch [1200/1397] Loss: 0.4255 Acc: 84.73% LR: 0.000053\n",
            "\n",
            "================================================================================\n",
            "üìä Epoch 58 Summary:\n",
            "================================================================================\n",
            "Train: Loss=0.4237, Acc=84.86%\n",
            "Val:   Loss=0.9891, Acc=74.89%\n",
            "LR: 0.000054\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Best model saved: 74.89%\n",
            "‚úÖ Curves saved: /content/drive/MyDrive/SkinDiseaseProject/training_curves.png\n",
            "\n",
            "================================================================================\n",
            "EPOCH 59/67\n",
            "================================================================================\n",
            "  Epoch [59/67] Batch [300/1397] Loss: 0.3692 Acc: 86.18% LR: 0.000065\n",
            "  Epoch [59/67] Batch [600/1397] Loss: 0.3819 Acc: 85.89% LR: 0.000075\n",
            "  Epoch [59/67] Batch [900/1397] Loss: 0.3927 Acc: 85.59% LR: 0.000086\n",
            "  Epoch [59/67] Batch [1200/1397] Loss: 0.4000 Acc: 85.42% LR: 0.000097\n",
            "\n",
            "================================================================================\n",
            "üìä Epoch 59 Summary:\n",
            "================================================================================\n",
            "Train: Loss=0.4075, Acc=85.22%\n",
            "Val:   Loss=1.0153, Acc=74.45%\n",
            "LR: 0.000104\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "EPOCH 60/67\n",
            "================================================================================\n",
            "\n",
            "‚ö†Ô∏è Training interrupted by user\n",
            "üíæ Checkpoint saved: epoch_60.pth\n",
            "\n",
            "================================================================================\n",
            "‚úÖ Training completed in 0.92 hours\n",
            "‚úÖ Best accuracy: 74.89%\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Curves saved: /content/drive/MyDrive/SkinDiseaseProject/training_curves.png\n"
          ]
        }
      ],
      "source": [
        "result = main_training_continuous()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as T\n",
        "\n",
        "def tta_predict(model, image, device='cuda'):\n",
        "    \"\"\"Test-Time Augmentation for better accuracy\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Define augmentations\n",
        "    augmentations = [\n",
        "        T.Lambda(lambda x: x),  # Original\n",
        "        T.RandomHorizontalFlip(p=1.0),  # Flip horizontal\n",
        "        T.RandomVerticalFlip(p=1.0),    # Flip vertical\n",
        "        T.Lambda(lambda x: torch.rot90(x, 1, [1, 2])),  # Rotate 90¬∞\n",
        "        T.Lambda(lambda x: torch.rot90(x, 2, [1, 2])),  # Rotate 180¬∞\n",
        "    ]\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for aug in augmentations:\n",
        "            # Apply augmentation\n",
        "            aug_image = aug(image).unsqueeze(0).to(device)\n",
        "\n",
        "            # Get prediction\n",
        "            logits, _, _ = model(aug_image)\n",
        "            probs = torch.softmax(logits, dim=1)\n",
        "            predictions.append(probs)\n",
        "\n",
        "    # Average predictions\n",
        "    avg_probs = torch.mean(torch.cat(predictions, dim=0), dim=0)\n",
        "\n",
        "    return avg_probs\n",
        "# Usage during testing\n",
        "image = load_test_image('test.jpg')\n",
        "final_prediction = tta_predict(model, image)\n",
        "predicted_class = torch.argmax(final_prediction)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "6vBqCkD7VfDZ",
        "outputId": "2ac87b78-b915-446e-b569-563c6855e08b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'load_test_image' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2540925162.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mavg_probs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Usage during testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_test_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mfinal_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtta_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mpredicted_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'load_test_image' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d8a0c68-0379-4083-99f5-7ce343e63c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAM10000 images loaded: 5000\n",
      "ISIC2019 images loaded: 25331\n",
      "Dermnet images loaded: 39118\n",
      "Total images before filtering: 69449\n",
      "Master CSV saved: master_skin_dataset_non_cancer.csv\n",
      "Total images after non-cancer filtering: 51077\n",
      "Train images: 40861, Test images: 10216\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# Merge HAM10000 + ISIC2019 + Dermnet datasets (non-cancer) + split\n",
    "# ======================================================================\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Base paths\n",
    "# -----------------------------\n",
    "HAM_PART1_PATH = r\"E:\\HAM10000_images_part_1\"\n",
    "HAM_PART2_PATH = r\"E:\\HAM10000_images_part_2\"\n",
    "HAM_META_PATH  = r\"C:\\Users\\achim\\OneDrive\\Documents\\HAM10000_metadata.csv\"\n",
    "\n",
    "ISIC_TRAIN_PATH = r\"E:\\ISIC_2019_Training_Input\\train\"\n",
    "ISIC_TEST_PATH  = r\"E:\\ISIC_2019_Training_Input\\test\"\n",
    "ISIC_FULL_PATH  = r\"E:\\ISIC_2019_Training_Input\\ISIC_2019_Training_Input\"\n",
    "ISIC_META_PATH  = r\"C:\\Users\\achim\\OneDrive\\Documents\\ISIC_2019_Training_Metadata.csv\"\n",
    "ISIC_GT_PATH    = r\"C:\\Users\\achim\\OneDrive\\Documents\\ISIC_2019_Training_GroundTruth.csv\"\n",
    "\n",
    "DERM_TRAIN_PATH = r\"E:\\train\"\n",
    "DERM_TEST_PATH  = r\"E:\\test\"\n",
    "\n",
    "MASTER_CSV_PATH = \"master_skin_dataset_non_cancer.csv\"\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Load HAM10000\n",
    "# -----------------------------\n",
    "def load_ham():\n",
    "    meta = pd.read_csv(HAM_META_PATH)\n",
    "    all_ham_images = glob(os.path.join(HAM_PART1_PATH, \"*.jpg\")) + glob(os.path.join(HAM_PART2_PATH, \"*.jpg\"))\n",
    "    img_dict = {os.path.splitext(os.path.basename(p))[0]: p for p in all_ham_images}\n",
    "\n",
    "    meta['image_path'] = meta['image_id'].map(img_dict)\n",
    "    df = meta[['image_path','dx']].copy()\n",
    "    df = df[df['image_path'].notna()]\n",
    "    df.rename(columns={'dx':'original_label'}, inplace=True)\n",
    "    print(f\"HAM10000 images loaded: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Load ISIC2019\n",
    "# -----------------------------\n",
    "def load_isic():\n",
    "    meta = pd.read_csv(ISIC_META_PATH)\n",
    "    gt   = pd.read_csv(ISIC_GT_PATH)\n",
    "\n",
    "    # Merge meta + GT on 'image'\n",
    "    df = meta.merge(gt, on='image', how='left')\n",
    "\n",
    "    # Winner-takes-all label for ISIC 2019\n",
    "    label_cols = ['MEL','NV','BCC','AK','BKL','DF','VASC','SCC']\n",
    "    df['original_label'] = df[label_cols].idxmax(axis=1)\n",
    "\n",
    "    # Map image filenames to actual paths\n",
    "    all_isic_images = []\n",
    "    for p in [ISIC_FULL_PATH, ISIC_TRAIN_PATH, ISIC_TEST_PATH]:\n",
    "        all_isic_images.extend(glob(os.path.join(p, \"*.jpg\")))\n",
    "    img_dict = {os.path.splitext(os.path.basename(p))[0]: p for p in all_isic_images}\n",
    "    df['image_path'] = df['image'].map(img_dict)\n",
    "\n",
    "    df = df[['image_path','original_label']].copy()\n",
    "    df = df[df['image_path'].notna()]\n",
    "    print(f\"ISIC2019 images loaded: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Load Dermnet\n",
    "# -----------------------------\n",
    "def load_dermnet():\n",
    "    rows = []\n",
    "    def collect(split_dir):\n",
    "        for cls in sorted(os.listdir(split_dir)):\n",
    "            cpath = os.path.join(split_dir, cls)\n",
    "            if not os.path.isdir(cpath): \n",
    "                continue\n",
    "            files = []\n",
    "            for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.JPG\",\"*.JPEG\",\"*.PNG\"):\n",
    "                files.extend(glob(os.path.join(cpath, ext)))\n",
    "            for fp in files:\n",
    "                rows.append((fp, cls))\n",
    "    collect(DERM_TRAIN_PATH)\n",
    "    collect(DERM_TEST_PATH)\n",
    "    df = pd.DataFrame(rows, columns=['image_path','original_label'])\n",
    "    print(f\"Dermnet images loaded: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Merge all datasets\n",
    "# -----------------------------\n",
    "ham_df    = load_ham()\n",
    "isic_df   = load_isic()\n",
    "dermnet_df= load_dermnet()\n",
    "\n",
    "master_df = pd.concat([ham_df,isic_df,dermnet_df],ignore_index=True)\n",
    "print(f\"Total images before filtering: {len(master_df)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Define unified mapping & cancer labels\n",
    "# -----------------------------\n",
    "UNIFIED_LABEL_MAPPING = {\n",
    "    'BKL': 'Benign Keratosis',\n",
    "    'DF': 'Dermatofibroma',\n",
    "    'NV': 'Nevus',\n",
    "    'VASC': 'Vascular Lesion',\n",
    "    # DermNet\n",
    "    'Acne and Rosacea Photos': 'Acne and Rosacea',\n",
    "    'Atopic Dermatitis Photos': 'Eczema',\n",
    "    'Bullous Disease Photos': 'Bullous Disease',\n",
    "    'Cellulitis Impetigo and other Bacterial Infections': 'Bacterial Infections',\n",
    "    'Eczema Photos': 'Eczema',\n",
    "    'Exanthems and Drug Eruptions': 'Drug Eruptions',\n",
    "    'Hair Loss Photos Alopecia and other Hair Diseases': 'Hair Disorders',\n",
    "    'Herpes HPV and other STDs Photos': 'STDs and Viral Infections',\n",
    "    'Light Diseases and Disorders of Pigmentation': 'Pigmentation Disorders',\n",
    "    'Lupus and other Connective Tissue diseases': 'Connective Tissue Diseases',\n",
    "    'Nail Fungus and other Nail Disease': 'Nail Disorders',\n",
    "    'Poison Ivy Photos and other Contact Dermatitis': 'Contact Dermatitis',\n",
    "    'Psoriasis pictures Lichen Planus and related diseases': 'Psoriasis and Lichen Planus',\n",
    "    'Scabies Lyme Disease and other Infestations and Bites': 'Infestations and Bites',\n",
    "    'Seborrheic Keratoses and other Benign Tumors': 'Benign Tumors',\n",
    "    'Systemic Disease': 'Systemic Disease',\n",
    "    'Tinea Ringworm Candidiasis and other Fungal Infections': 'Fungal Infections',\n",
    "    'Urticaria Hives': 'Urticaria',\n",
    "    'Vascular Tumors': 'Vascular Tumors',\n",
    "    'Vasculitis Photos': 'Vasculitis',\n",
    "    'Warts Molluscum and other Viral Infections': 'Viral Infections',\n",
    "}\n",
    "\n",
    "CANCER_LABELS_TO_EXCLUDE = {'MEL','BCC','SCC','AK',\n",
    "                            'Melanoma Skin Cancer Nevi and Moles',\n",
    "                            'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions'}\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Remove cancer data & map unified labels\n",
    "# -----------------------------\n",
    "cancer_mask = master_df['original_label'].isin(CANCER_LABELS_TO_EXCLUDE)\n",
    "master_df = master_df[~cancer_mask].copy()\n",
    "master_df['unified_label'] = master_df['original_label'].map(UNIFIED_LABEL_MAPPING)\n",
    "\n",
    "# Remove any rows not mapped\n",
    "master_df = master_df[master_df['unified_label'].notna()]\n",
    "\n",
    "# Assign numeric label_id\n",
    "master_df['label_id'] = master_df['unified_label'].astype('category').cat.codes\n",
    "\n",
    "# Verify all image files exist\n",
    "master_df = master_df[master_df['image_path'].apply(os.path.exists)]\n",
    "\n",
    "# Save master CSV\n",
    "master_df[['image_path','unified_label','label_id']].to_csv(MASTER_CSV_PATH, index=False)\n",
    "print(f\"Master CSV saved: {MASTER_CSV_PATH}\")\n",
    "print(f\"Total images after non-cancer filtering: {len(master_df)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 8) Train/Test split\n",
    "# -----------------------------\n",
    "train_df, test_df = train_test_split(master_df, test_size=0.2, stratify=master_df['label_id'], random_state=42)\n",
    "train_df.to_csv(\"train_dataset.csv\", index=False)\n",
    "test_df.to_csv(\"test_dataset.csv\", index=False)\n",
    "print(f\"Train images: {len(train_df)}, Test images: {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad7a7d2-12b0-402e-8a6f-faacd00e93b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "GPU Memory: 8.0 GB\n",
      "‚úÖ Model code loaded successfully!\n",
      "üìù Next steps:\n",
      "1. Make sure your train_dataset.csv and test_dataset.csv are in the current directory\n",
      "2. Run the training code below\n"
     ]
    }
   ],
   "source": [
    "# ELSA + Adaptive Vision Transformer Model\n",
    "# Optimized for RTX 3070 GPU\n",
    "\n",
    "# =========================\n",
    "# Install Dependencies (Run this first)\n",
    "# =========================\n",
    "# !pip install torch torchvision timm matplotlib pandas scikit-learn pillow\n",
    "\n",
    "# =========================\n",
    "# Imports\n",
    "# =========================\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Function\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "\n",
    "from timm.layers import DropPath, trunc_normal_, Mlp\n",
    "from timm.utils import accuracy\n",
    "\n",
    "# Set device - Your RTX 3070\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "# =========================\n",
    "# Custom Dataset for CSV files\n",
    "# =========================\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['image_path']\n",
    "        label = self.df.iloc[idx]['label_id']\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "# =========================\n",
    "# ELSA Implementation\n",
    "# =========================\n",
    "class ELSAFunctionCUDA(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, features, ghost_mul, ghost_add, h_attn,\n",
    "                kernel_size=5, dilation=1, stride=1, version=''):\n",
    "        # CPU fallback implementation for compatibility\n",
    "        B, C, H, W = features.shape\n",
    "        _pad = kernel_size // 2 * dilation\n",
    "        features_unfolded = F.unfold(\n",
    "            features, kernel_size=kernel_size, dilation=dilation, padding=_pad, stride=stride) \\\n",
    "            .reshape(B, C, kernel_size ** 2, H * W)\n",
    "\n",
    "        if ghost_mul is not None:\n",
    "            ghost_mul = ghost_mul.reshape(B, C, kernel_size ** 2, 1)\n",
    "        if ghost_add is not None:\n",
    "            ghost_add = ghost_add.reshape(B, C, kernel_size ** 2, 1)\n",
    "\n",
    "        h_attn = h_attn.reshape(B, 1, kernel_size ** 2, H * W)\n",
    "\n",
    "        # Compute filters\n",
    "        if ghost_mul is not None and ghost_add is not None:\n",
    "            filters = ghost_mul * h_attn + ghost_add\n",
    "        elif ghost_mul is not None:\n",
    "            filters = ghost_mul * h_attn\n",
    "        elif ghost_add is not None:\n",
    "            filters = h_attn + ghost_add\n",
    "        else:\n",
    "            filters = h_attn\n",
    "\n",
    "        return (features_unfolded * filters).sum(2).reshape(B, C, H, W)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output, None, None, None, None, None, None, None\n",
    "\n",
    "def elsa_op(features, ghost_mul, ghost_add, h_attn, lam, gamma,\n",
    "            kernel_size=5, dilation=1, stride=1, version=''):\n",
    "\n",
    "    _B, _C = features.shape[:2]\n",
    "    ks = kernel_size\n",
    "\n",
    "    if ghost_mul is not None:\n",
    "        ghost_mul = ghost_mul ** lam if lam != 0 else None\n",
    "    if ghost_add is not None:\n",
    "        ghost_add = ghost_add * gamma if gamma != 0 else None\n",
    "\n",
    "    B, C, H, W = features.shape\n",
    "    _pad = kernel_size // 2 * dilation\n",
    "    features_unfolded = F.unfold(\n",
    "        features, kernel_size=kernel_size, dilation=dilation, padding=_pad, stride=stride) \\\n",
    "        .reshape(B, C, kernel_size ** 2, H * W)\n",
    "\n",
    "    if ghost_mul is not None:\n",
    "        ghost_mul = ghost_mul.reshape(B, C, kernel_size ** 2, 1)\n",
    "    if ghost_add is not None:\n",
    "        ghost_add = ghost_add.reshape(B, C, kernel_size ** 2, 1)\n",
    "\n",
    "    h_attn = h_attn.reshape(B, 1, kernel_size ** 2, H * W)\n",
    "\n",
    "    # Compute filters\n",
    "    if ghost_mul is not None and ghost_add is not None:\n",
    "        filters = ghost_mul * h_attn + ghost_add\n",
    "    elif ghost_mul is not None:\n",
    "        filters = ghost_mul * h_attn\n",
    "    elif ghost_add is not None:\n",
    "        filters = h_attn + ghost_add\n",
    "    else:\n",
    "        filters = h_attn\n",
    "\n",
    "    return (features_unfolded * filters).sum(2).reshape(B, C, H, W)\n",
    "\n",
    "class ELSA(nn.Module):\n",
    "    \"\"\"Enhanced Local Self-Attention\"\"\"\n",
    "    def __init__(self, dim, num_heads, dim_qk=None, dim_v=None, kernel_size=5,\n",
    "                 stride=1, dilation=1, qkv_bias=False, qk_scale=None,\n",
    "                 attn_drop=0., proj_drop=0., group_width=8, groups=1, lam=1,\n",
    "                 gamma=1, **kwargs):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dim_qk = dim_qk or self.dim // 3 * 2\n",
    "        self.dim_v = dim_v or dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "\n",
    "        head_dim = self.dim_v // num_heads\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        if self.dim_qk % group_width != 0:\n",
    "            self.dim_qk = math.ceil(float(self.dim_qk) / group_width) * group_width\n",
    "\n",
    "        self.group_width = group_width\n",
    "        self.groups = groups\n",
    "        self.lam = lam\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.pre_proj = nn.Conv2d(dim, self.dim_qk * 2 + self.dim_v, 1, bias=qkv_bias)\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Conv2d(self.dim_qk, self.dim_qk, kernel_size, padding=(kernel_size // 2)*dilation,\n",
    "                      dilation=dilation, groups=self.dim_qk // group_width),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(self.dim_qk, kernel_size ** 2 * num_heads, 1, groups=groups))\n",
    "\n",
    "        if self.lam != 0 and self.gamma != 0:\n",
    "            ghost_mul = torch.randn(1, 1, self.dim_v, kernel_size, kernel_size)\n",
    "            ghost_add = torch.zeros(1, 1, self.dim_v, kernel_size, kernel_size)\n",
    "            trunc_normal_(ghost_add, std=.02)\n",
    "            self.ghost_head = nn.Parameter(torch.cat((ghost_mul, ghost_add), dim=0), requires_grad=True)\n",
    "        elif self.lam == 0 and self.gamma != 0:\n",
    "            ghost_add = torch.zeros(1, self.dim_v, kernel_size, kernel_size)\n",
    "            trunc_normal_(ghost_add, std=.02)\n",
    "            self.ghost_head = nn.Parameter(ghost_add, requires_grad=True)\n",
    "        elif self.lam != 0 and self.gamma == 0:\n",
    "            ghost_mul = torch.randn(1, self.dim_v, kernel_size, kernel_size)\n",
    "            self.ghost_head = nn.Parameter(ghost_mul, requires_grad=True)\n",
    "        else:\n",
    "            self.ghost_head = None\n",
    "\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.post_proj = nn.Linear(self.dim_v, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        B, H, W, _ = x.shape\n",
    "        C = self.dim_v\n",
    "        ks = self.kernel_size\n",
    "        G = self.num_heads\n",
    "        x = x.permute(0, 3, 1, 2)  # B, C, H, W\n",
    "\n",
    "        qkv = self.pre_proj(x)\n",
    "        q, k, v = torch.split(qkv, (self.dim_qk, self.dim_qk, self.dim_v), dim=1)\n",
    "        hadamard_product = q * k * self.scale\n",
    "\n",
    "        if self.stride > 1:\n",
    "            hadamard_product = F.avg_pool2d(hadamard_product, self.stride)\n",
    "\n",
    "        h_attn = self.attn(hadamard_product)\n",
    "        v = v.reshape(B * G, C // G, H, W)\n",
    "        h_attn = h_attn.reshape(B * G, -1, H, W).softmax(1)\n",
    "        h_attn = self.attn_drop(h_attn)\n",
    "\n",
    "        ghost_mul = None\n",
    "        ghost_add = None\n",
    "        if self.lam != 0 and self.gamma != 0:\n",
    "            gh = self.ghost_head.expand(2, B, C, ks, ks).reshape(2, B * G, C // G, ks, ks)\n",
    "            ghost_mul, ghost_add = gh[0], gh[1]\n",
    "        elif self.lam == 0 and self.gamma != 0:\n",
    "            ghost_add = self.ghost_head.expand(B, C, ks, ks).reshape(B * G, C // G, ks, ks)\n",
    "        elif self.lam != 0 and self.gamma == 0:\n",
    "            ghost_mul = self.ghost_head.expand(B, C, ks, ks).reshape(B * G, C // G, ks, ks)\n",
    "\n",
    "        x = elsa_op(v, ghost_mul, ghost_add, h_attn, self.lam, self.gamma,\n",
    "                    self.kernel_size, self.dilation, self.stride)\n",
    "        x = x.reshape(B, C, H // self.stride, W // self.stride)\n",
    "        x = self.post_proj(x.permute(0, 2, 3, 1))  # B, H, W, C\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "class ELSABlock(nn.Module):\n",
    "    \"\"\"ELSA block: ELSA + MLP\"\"\"\n",
    "    def __init__(self, dim, kernel_size, stride=1, num_heads=1, mlp_ratio=3.,\n",
    "                 drop=0., attn_drop=0., drop_path=0., act_layer=nn.GELU, \n",
    "                 norm_layer=nn.LayerNorm, qkv_bias=False, qk_scale=1, \n",
    "                 dim_qk=None, dim_v=None, lam=1, gamma=1, dilation=1, \n",
    "                 group_width=8, groups=1, **kwargs):\n",
    "        super().__init__()\n",
    "        assert stride == 1\n",
    "        self.dim = dim\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = ELSA(dim, num_heads, dim_qk=dim_qk, dim_v=dim_v, \n",
    "                         kernel_size=kernel_size, stride=stride, dilation=dilation,\n",
    "                         qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop,\n",
    "                         group_width=group_width, groups=groups, lam=lam, gamma=gamma)\n",
    "\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, \n",
    "                       act_layer=act_layer, drop=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.drop_path(self.attn(self.norm1(x)))\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "# =========================\n",
    "# Vision Transformer Components\n",
    "# =========================\n",
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=384):\n",
    "        super().__init__()\n",
    "        assert img_size % patch_size == 0\n",
    "        self.num_patches = (img_size // patch_size) * (img_size // patch_size)\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)                 # (B, C, H/ps, W/ps)\n",
    "        x = x.flatten(2).transpose(1, 2) # (B, N, C)\n",
    "        return x\n",
    "\n",
    "class AdaptiveAttention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=6, qkv_bias=True, attn_drop=0., proj_drop=0.,\n",
    "                 ada_head=False, head_select_tau=5.0):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = dim // num_heads\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "        self.ada_head = ada_head\n",
    "        self.head_select_tau = head_select_tau\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "        if ada_head:\n",
    "            self.head_select = nn.Linear(dim, num_heads)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "\n",
    "        attn_scores = (q @ k.transpose(-2, -1)) * self.scale\n",
    "\n",
    "        head_policy = None\n",
    "        if self.ada_head:\n",
    "            cls_embed = x[:, 0]\n",
    "            logits = self.head_select(cls_embed)\n",
    "            head_policy = F.gumbel_softmax(logits / self.head_select_tau, hard=True, dim=-1)\n",
    "            attn_scores = attn_scores * head_policy.unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        attn = attn_scores.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        out = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        out = self.proj(out)\n",
    "        out = self.proj_drop(out)\n",
    "        return out, head_policy\n",
    "\n",
    "class AdaptiveBlock(nn.Module):\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=True, drop=0., \n",
    "                 attn_drop=0., drop_path=0., ada_head=False, head_select_tau=5.0):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = AdaptiveAttention(\n",
    "            dim, num_heads=num_heads, qkv_bias=qkv_bias, attn_drop=attn_drop, \n",
    "            proj_drop=drop, ada_head=ada_head, head_select_tau=head_select_tau\n",
    "        )\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0 else nn.Identity()\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "\n",
    "        hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(drop),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_in = self.norm1(x)\n",
    "        attn_out, head_policy = self.attn(attn_in)\n",
    "        x = x + self.drop_path(attn_out)\n",
    "        \n",
    "        mlp_in = self.norm2(x)\n",
    "        x = x + self.drop_path(self.mlp(mlp_in))\n",
    "        \n",
    "        return x, head_policy\n",
    "\n",
    "# =========================\n",
    "# Main Model: ELSA + Adaptive ViT\n",
    "# =========================\n",
    "class AdaptiveViTWithELSA(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, num_classes=1000,\n",
    "                 embed_dim=384, depth=8, num_heads=6, mlp_ratio=4.,\n",
    "                 drop_rate=0.1, drop_path_rate=0.1, ada_head=True, ada_layer=True,\n",
    "                 head_select_tau=5.0, layer_select_tau=5.0, use_elsa=True, \n",
    "                 elsa_kernel_size=5, elsa_num_heads=6, elsa_mlp_ratio=3.0, \n",
    "                 elsa_lam=1.0, elsa_gamma=1.0):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.embed_dim = embed_dim\n",
    "        self.depth = depth\n",
    "        self.ada_head = ada_head\n",
    "        self.ada_layer = ada_layer\n",
    "        self.layer_select_tau = layer_select_tau\n",
    "        self.use_elsa = use_elsa\n",
    "\n",
    "        self.patch_embed = PatchEmbed(img_size, patch_size, in_chans, embed_dim)\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "\n",
    "        # ELSA block after patch embedding\n",
    "        if use_elsa:\n",
    "            self.elsa_block = ELSABlock(\n",
    "                dim=embed_dim, kernel_size=elsa_kernel_size, num_heads=elsa_num_heads,\n",
    "                mlp_ratio=elsa_mlp_ratio, drop=drop_rate, attn_drop=0.0,\n",
    "                drop_path=0.0, lam=elsa_lam, gamma=elsa_gamma\n",
    "            )\n",
    "\n",
    "        # Adaptive Vision Transformer blocks\n",
    "        dpr = torch.linspace(0, drop_path_rate, steps=depth).tolist()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            AdaptiveBlock(\n",
    "                embed_dim, num_heads, mlp_ratio=mlp_ratio, qkv_bias=True, \n",
    "                drop=drop_rate, attn_drop=0.0, drop_path=dpr[i], ada_head=ada_head,\n",
    "                head_select_tau=head_select_tau\n",
    "            ) for i in range(depth)\n",
    "        ])\n",
    "\n",
    "        if ada_layer:\n",
    "            self.layer_select = nn.Linear(embed_dim, depth)\n",
    "\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.head = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "        trunc_normal_(self.pos_embed, std=0.02)\n",
    "        trunc_normal_(self.cls_token, std=0.02)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    @staticmethod\n",
    "    def _init_weights(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=0.02)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.patch_embed(x)\n",
    "        cls = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat([cls, x], dim=1)\n",
    "        x = x + self.pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        # Apply ELSA after patch embedding\n",
    "        if self.use_elsa:\n",
    "            patch_dim = int(math.sqrt(x.shape[1] - 1))\n",
    "            cls_token = x[:, 0:1, :]\n",
    "            patch_tokens = x[:, 1:, :]\n",
    "            \n",
    "            # Reshape to spatial format for ELSA\n",
    "            patch_tokens = patch_tokens.reshape(B, patch_dim, patch_dim, self.embed_dim)\n",
    "            patch_tokens = self.elsa_block(patch_tokens)\n",
    "            patch_tokens = patch_tokens.reshape(B, patch_dim * patch_dim, self.embed_dim)\n",
    "            \n",
    "            # Concatenate CLS token back\n",
    "            x = torch.cat([cls_token, patch_tokens], dim=1)\n",
    "\n",
    "        head_policies = []\n",
    "        layer_policy = None\n",
    "\n",
    "        if self.ada_layer:\n",
    "            with torch.no_grad():\n",
    "                logits = self.layer_select(x[:, 0])\n",
    "                layer_policy = F.gumbel_softmax(logits / self.layer_select_tau, hard=True, dim=-1)\n",
    "\n",
    "        for i, blk in enumerate(self.blocks):\n",
    "            if self.ada_layer and layer_policy is not None:\n",
    "                if (layer_policy[:, i].sum() == 0):\n",
    "                    head_policies.append(None)\n",
    "                    continue\n",
    "            x, h_pol = blk(x)\n",
    "            head_policies.append(h_pol)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        return x[:, 0], head_policies, layer_policy\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats, head_policies, layer_policy = self.forward_features(x)\n",
    "        logits = self.head(feats)\n",
    "\n",
    "        head_select = None\n",
    "        if self.ada_head and any(p is not None for p in head_policies):\n",
    "            valid = [p for p in head_policies if p is not None]\n",
    "            if len(valid) > 0:\n",
    "                head_select = torch.stack(valid, dim=1).mean(dim=1)\n",
    "\n",
    "        return logits, head_select, layer_policy\n",
    "\n",
    "# =========================\n",
    "# Loss Function\n",
    "# =========================\n",
    "class AdaptiveEfficiencyLoss(nn.Module):\n",
    "    def __init__(self, class_counts=None, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        if class_counts is not None:\n",
    "            class_weights = 1.0 / torch.tensor(class_counts, dtype=torch.float32)\n",
    "            class_weights = class_weights / class_weights.sum()\n",
    "            self.ce = nn.CrossEntropyLoss(weight=class_weights.to(device), label_smoothing=smoothing)\n",
    "        else:\n",
    "            self.ce = nn.CrossEntropyLoss(label_smoothing=smoothing)\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        return self.ce(logits, targets)\n",
    "\n",
    "# =========================\n",
    "# Data Transforms\n",
    "# =========================\n",
    "def get_transforms(img_size=224):\n",
    "    train_transform = T.Compose([\n",
    "        T.Resize((img_size, img_size)),\n",
    "        T.RandomRotation(15),\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        T.ToTensor(),\n",
    "        T.RandomErasing(p=0.2),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    val_transform = T.Compose([\n",
    "        T.Resize((img_size, img_size)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform\n",
    "\n",
    "# =========================\n",
    "# Training Functions\n",
    "# =========================\n",
    "def train_one_epoch(model, loader, optimizer, loss_fn, device, epoch, scheduler=None, log_interval=50):\n",
    "    model.train()\n",
    "    losses, top1s = [], []\n",
    "    head_ratios, layer_ratios = [], []\n",
    "\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits, head_policy, layer_policy = model(x)\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        if head_policy is not None:\n",
    "            head_ratios.append(head_policy.mean().item())\n",
    "        if layer_policy is not None:\n",
    "            layer_ratios.append(layer_policy.float().mean().item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        acc1, _ = accuracy(logits, y, topk=(1, 5))\n",
    "        losses.append(loss.item())\n",
    "        top1s.append(acc1.item())\n",
    "\n",
    "        if (i + 1) % log_interval == 0:\n",
    "            print(f\"Epoch {epoch} | Step {i+1}/{len(loader)} | \"\n",
    "                  f\"Loss {np.mean(losses):.4f} | Acc@1 {np.mean(top1s):.2f}%\")\n",
    "\n",
    "    return {\n",
    "        \"loss\": float(np.mean(losses)),\n",
    "        \"acc1\": float(np.mean(top1s)),\n",
    "        \"head\": float(np.mean(head_ratios)) if head_ratios else 0.0,\n",
    "        \"layer\": float(np.mean(layer_ratios)) if layer_ratios else 0.0,\n",
    "    }\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    losses, top1s = [], []\n",
    "    head_ratios, layer_ratios = [], []\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits, head_policy, layer_policy = model(x)\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        if head_policy is not None:\n",
    "            head_ratios.append(head_policy.mean().item())\n",
    "        if layer_policy is not None:\n",
    "            layer_ratios.append(layer_policy.float().mean().item())\n",
    "\n",
    "        acc1, _ = accuracy(logits, y, topk=(1, 5))\n",
    "        losses.append(loss.item())\n",
    "        top1s.append(acc1.item())\n",
    "\n",
    "    return {\n",
    "        \"val_loss\": float(np.mean(losses)),\n",
    "        \"val_acc1\": float(np.mean(top1s)),\n",
    "        \"val_head\": float(np.mean(head_ratios)) if head_ratios else 0.0,\n",
    "        \"val_layer\": float(np.mean(layer_ratios)) if layer_ratios else 0.0,\n",
    "    }\n",
    "\n",
    "def plot_curves(history, save_path=\"training_curves.png\"):\n",
    "    epochs = len(history['train']['loss'])\n",
    "    x = range(1, epochs + 1)\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, history['train']['loss'], label='Train Loss', marker='o')\n",
    "    plt.plot(x, history['val']['loss'], label='Val Loss', marker='s')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Curves')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, history['train']['acc'], label='Train Acc@1', marker='o')\n",
    "    plt.plot(x, history['val']['acc'], label='Val Acc@1', marker='s')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Accuracy Curves')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=200, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# =========================\n",
    "# Configuration Class\n",
    "# =========================\n",
    "class Config:\n",
    "    # Data\n",
    "    train_csv = \"train_dataset.csv\"\n",
    "    test_csv = \"test_dataset.csv\"\n",
    "    img_size = 224\n",
    "    batch_size = 8  # Reduced for RTX 3070 8GB VRAM\n",
    "    num_workers = 4\n",
    "\n",
    "    # Model architecture\n",
    "    patch_size = 16\n",
    "    embed_dim = 384\n",
    "    depth = 8\n",
    "    num_heads = 6\n",
    "    mlp_ratio = 4.0\n",
    "    drop_rate = 0.1\n",
    "    drop_path_rate = 0.1\n",
    "\n",
    "    # ELSA parameters\n",
    "    use_elsa = True\n",
    "    elsa_kernel_size = 5\n",
    "    elsa_num_heads = 6\n",
    "    elsa_mlp_ratio = 3.0\n",
    "    elsa_lam = 1.0\n",
    "    elsa_gamma = 1.0\n",
    "\n",
    "    # Training\n",
    "    epochs = 25\n",
    "    lr = 3e-4\n",
    "    weight_decay = 0.05\n",
    "    max_lr = 1e-3\n",
    "    \n",
    "    # Save paths\n",
    "    ckpt_path = \"best_elsa_adaptive_vit.pth\"\n",
    "    plot_path = \"training_curves.png\"\n",
    "\n",
    "# Initialize config\n",
    "config = Config()\n",
    "\n",
    "print(\"‚úÖ Model code loaded successfully!\")\n",
    "print(\"üìù Next steps:\")\n",
    "print(\"1. Make sure your train_dataset.csv and test_dataset.csv are in the current directory\")\n",
    "print(\"2. Run the training code below\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3d6222f-7473-4169-8206-6fbe07080e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ GPU Test:\n",
      "   CUDA available: True\n",
      "   GPU name: NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "   GPU memory: 8.0 GB\n",
      "   ‚úÖ GPU computation successful!\n",
      "   Tensor device: cuda:0\n",
      "\n",
      "============================================================\n",
      "üöÄ ELSA + Adaptive Vision Transformer Ready!\n",
      "============================================================\n",
      "\n",
      "üìã Available functions:\n",
      "   ‚Ä¢ main() - Start training\n",
      "   ‚Ä¢ test_model() - Test the trained model\n",
      "   ‚Ä¢ predict_single_image(path) - Predict single image\n",
      "   ‚Ä¢ gpu_test() - Test GPU functionality\n",
      "\n",
      "üí° To start training, run: main()\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Training Script for ELSA + Adaptive Vision Transformer\n",
    "# Optimized for RTX 3070 GPU\n",
    "# =========================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main training function\"\"\"\n",
    "    \n",
    "    # Check if CSV files exist\n",
    "    if not os.path.exists(config.train_csv):\n",
    "        print(f\"‚ùå Error: {config.train_csv} not found!\")\n",
    "        print(\"Please make sure your train_dataset.csv is in the current directory\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(config.test_csv):\n",
    "        print(f\"‚ùå Error: {config.test_csv} not found!\")\n",
    "        print(\"Please make sure your test_dataset.csv is in the current directory\")\n",
    "        return\n",
    "    \n",
    "    print(\"üìÇ Loading datasets...\")\n",
    "    \n",
    "    # Get data transforms\n",
    "    train_transform, val_transform = get_transforms(config.img_size)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = CustomImageDataset(config.train_csv, transform=train_transform)\n",
    "    val_dataset = CustomImageDataset(config.test_csv, transform=val_transform)\n",
    "    \n",
    "    print(f\"üìä Dataset Info:\")\n",
    "    print(f\"   Training samples: {len(train_dataset)}\")\n",
    "    print(f\"   Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # Get number of classes from the dataset\n",
    "    train_df = pd.read_csv(config.train_csv)\n",
    "    num_classes = train_df['label_id'].nunique()\n",
    "    class_counts = train_df['label_id'].value_counts().sort_index().values\n",
    "    \n",
    "    print(f\"   Number of classes: {num_classes}\")\n",
    "    print(f\"   Class distribution: {class_counts}\")\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=True,\n",
    "        num_workers=config.num_workers, \n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=False,\n",
    "        num_workers=config.num_workers, \n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"üîß Building model...\")\n",
    "    \n",
    "    # Create model\n",
    "    model = AdaptiveViTWithELSA(\n",
    "        img_size=config.img_size,\n",
    "        patch_size=config.patch_size,\n",
    "        num_classes=num_classes,\n",
    "        embed_dim=config.embed_dim,\n",
    "        depth=config.depth,\n",
    "        num_heads=config.num_heads,\n",
    "        mlp_ratio=config.mlp_ratio,\n",
    "        drop_rate=config.drop_rate,\n",
    "        drop_path_rate=config.drop_path_rate,\n",
    "        use_elsa=config.use_elsa,\n",
    "        elsa_kernel_size=config.elsa_kernel_size,\n",
    "        elsa_num_heads=config.elsa_num_heads,\n",
    "        elsa_mlp_ratio=config.elsa_mlp_ratio,\n",
    "        elsa_lam=config.elsa_lam,\n",
    "        elsa_gamma=config.elsa_gamma\n",
    "    ).to(device)\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"üèóÔ∏è  Model Info:\")\n",
    "    print(f\"   Total parameters: {total_params:,}\")\n",
    "    print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"   Model size: ~{total_params * 4 / 1024**2:.1f} MB\")\n",
    "    \n",
    "    # Create optimizer and scheduler\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=config.lr, \n",
    "        weight_decay=config.weight_decay\n",
    "    )\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, \n",
    "        max_lr=config.max_lr, \n",
    "        steps_per_epoch=len(train_loader), \n",
    "        epochs=config.epochs\n",
    "    )\n",
    "    \n",
    "    # Create loss function with class balancing\n",
    "    loss_fn = AdaptiveEfficiencyLoss(class_counts=class_counts.tolist())\n",
    "    \n",
    "    print(f\"üöÄ Starting training...\")\n",
    "    print(f\"   Device: {device}\")\n",
    "    print(f\"   Batch size: {config.batch_size}\")\n",
    "    print(f\"   Epochs: {config.epochs}\")\n",
    "    print(f\"   Learning rate: {config.lr}\")\n",
    "    print(f\"   Max learning rate: {config.max_lr}\")\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        \"train\": {\"loss\": [], \"acc\": []},\n",
    "        \"val\": {\"loss\": [], \"acc\": []},\n",
    "    }\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(1, config.epochs + 1):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Epoch {epoch}/{config.epochs}\")\n",
    "        print('='*50)\n",
    "        \n",
    "        # Train\n",
    "        train_info = train_one_epoch(\n",
    "            model, train_loader, optimizer, loss_fn, device, epoch, scheduler\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        val_info = validate(model, val_loader, loss_fn, device)\n",
    "        \n",
    "        # Print epoch results\n",
    "        print(f\"\\nüìä Epoch {epoch} Results:\")\n",
    "        print(f\"   Train Loss: {train_info['loss']:.4f} | Train Acc@1: {train_info['acc1']:.2f}%\")\n",
    "        print(f\"   Val Loss:   {val_info['val_loss']:.4f} | Val Acc@1:   {val_info['val_acc1']:.2f}%\")\n",
    "        \n",
    "        if train_info['head'] > 0:\n",
    "            print(f\"   Head Selection: {train_info['head']:.3f} | Layer Selection: {train_info['layer']:.3f}\")\n",
    "        \n",
    "        # Update history\n",
    "        history['train']['loss'].append(train_info['loss'])\n",
    "        history['train']['acc'].append(train_info['acc1'])\n",
    "        history['val']['loss'].append(val_info['val_loss'])\n",
    "        history['val']['acc'].append(val_info['val_acc1'])\n",
    "        \n",
    "        # Save best model\n",
    "        if val_info['val_acc1'] > best_acc:\n",
    "            best_acc = val_info['val_acc1']\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'best_acc': best_acc,\n",
    "                'config': config,\n",
    "            }, config.ckpt_path)\n",
    "            print(f\"   üíæ Saved new best model! (Acc@1: {best_acc:.2f}%)\")\n",
    "        \n",
    "        # GPU memory info\n",
    "        if torch.cuda.is_available():\n",
    "            memory_used = torch.cuda.max_memory_allocated() / 1024**3\n",
    "            print(f\"   üî• GPU Memory: {memory_used:.2f} GB / 8.0 GB\")\n",
    "    \n",
    "    # Training completed\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nüéâ Training completed!\")\n",
    "    print(f\"   Total time: {total_time/3600:.2f} hours\")\n",
    "    print(f\"   Best validation accuracy: {best_acc:.2f}%\")\n",
    "    print(f\"   Model saved to: {config.ckpt_path}\")\n",
    "    \n",
    "    # Plot training curves\n",
    "    print(f\"\\nüìà Plotting training curves...\")\n",
    "    plot_curves(history, config.plot_path)\n",
    "    print(f\"   Curves saved to: {config.plot_path}\")\n",
    "    \n",
    "    return model, history, best_acc\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"Test the trained model\"\"\"\n",
    "    if not os.path.exists(config.ckpt_path):\n",
    "        print(f\"‚ùå No saved model found at {config.ckpt_path}\")\n",
    "        return\n",
    "    \n",
    "    print(\"üîç Loading best model for testing...\")\n",
    "    \n",
    "    # Load the saved model\n",
    "    checkpoint = torch.load(config.ckpt_path)\n",
    "    \n",
    "    # Get number of classes\n",
    "    train_df = pd.read_csv(config.train_csv)\n",
    "    num_classes = train_df['label_id'].nunique()\n",
    "    \n",
    "    # Recreate model\n",
    "    model = AdaptiveViTWithELSA(\n",
    "        img_size=config.img_size,\n",
    "        patch_size=config.patch_size,\n",
    "        num_classes=num_classes,\n",
    "        embed_dim=config.embed_dim,\n",
    "        depth=config.depth,\n",
    "        num_heads=config.num_heads,\n",
    "        mlp_ratio=config.mlp_ratio,\n",
    "        drop_rate=config.drop_rate,\n",
    "        drop_path_rate=config.drop_path_rate,\n",
    "        use_elsa=config.use_elsa,\n",
    "        elsa_kernel_size=config.elsa_kernel_size,\n",
    "        elsa_num_heads=config.elsa_num_heads,\n",
    "        elsa_mlp_ratio=config.elsa_mlp_ratio,\n",
    "        elsa_lam=config.elsa_lam,\n",
    "        elsa_gamma=config.elsa_gamma\n",
    "    ).to(device)\n",
    "    \n",
    "    # Load weights\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    # Test on validation set\n",
    "    _, val_transform = get_transforms(config.img_size)\n",
    "    val_dataset = CustomImageDataset(config.test_csv, transform=val_transform)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "    \n",
    "    # Simple test\n",
    "    loss_fn = AdaptiveEfficiencyLoss()\n",
    "    test_results = validate(model, val_loader, loss_fn, device)\n",
    "    \n",
    "    print(f\"üéØ Test Results:\")\n",
    "    print(f\"   Test Accuracy: {test_results['val_acc1']:.2f}%\")\n",
    "    print(f\"   Test Loss: {test_results['val_loss']:.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_single_image(image_path, model=None):\n",
    "    \"\"\"Predict a single image\"\"\"\n",
    "    if model is None:\n",
    "        model = test_model()\n",
    "    \n",
    "    if model is None:\n",
    "        return None\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    _, val_transform = get_transforms(config.img_size)\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image_tensor = val_transform(image).unsqueeze(0).to(device)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits, _, _ = model(image_tensor)\n",
    "            probabilities = F.softmax(logits, dim=1)\n",
    "            predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "            confidence = probabilities[0][predicted_class].item()\n",
    "        \n",
    "        print(f\"üîÆ Prediction for {image_path}:\")\n",
    "        print(f\"   Predicted class: {predicted_class}\")\n",
    "        print(f\"   Confidence: {confidence:.4f}\")\n",
    "        \n",
    "        return predicted_class, confidence\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error predicting image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# =========================\n",
    "# Quick GPU Test\n",
    "# =========================\n",
    "def gpu_test():\n",
    "    \"\"\"Quick test to ensure GPU is working\"\"\"\n",
    "    print(\"üß™ GPU Test:\")\n",
    "    print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"   GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"   GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "        \n",
    "        # Simple tensor operations\n",
    "        x = torch.randn(1000, 1000).cuda()\n",
    "        y = torch.randn(1000, 1000).cuda()\n",
    "        z = torch.matmul(x, y)\n",
    "        \n",
    "        print(f\"   ‚úÖ GPU computation successful!\")\n",
    "        print(f\"   Tensor device: {z.device}\")\n",
    "        \n",
    "        # Clear memory\n",
    "        del x, y, z\n",
    "        torch.cuda.empty_cache()\n",
    "    else:\n",
    "        print(\"   ‚ùå GPU not available - will use CPU (very slow)\")\n",
    "\n",
    "# Run GPU test\n",
    "gpu_test()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ ELSA + Adaptive Vision Transformer Ready!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüìã Available functions:\")\n",
    "print(\"   ‚Ä¢ main() - Start training\")\n",
    "print(\"   ‚Ä¢ test_model() - Test the trained model\") \n",
    "print(\"   ‚Ä¢ predict_single_image(path) - Predict single image\")\n",
    "print(\"   ‚Ä¢ gpu_test() - Test GPU functionality\")\n",
    "print(\"\\nüí° To start training, run: main()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf0740c-ae68-40fe-aacc-7063f8491122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading datasets...\n",
      "üìä Dataset Info:\n",
      "   Training samples: 28068\n",
      "   Validation samples: 7018\n",
      "   Number of classes: 20\n",
      "   Class distribution: [1843  578 2742  898  840  520  808 3449 2600  478  862 2081 1138 2811\n",
      "  811 1213  424  965  834 2173]\n",
      "üîß Building model...\n",
      "üèóÔ∏è  Model Info:\n",
      "   Total parameters: 16,085,986\n",
      "   Trainable parameters: 16,085,986\n",
      "   Model size: ~61.4 MB\n",
      "üöÄ Starting training...\n",
      "   Device: cuda\n",
      "   Batch size: 8\n",
      "   Epochs: 20\n",
      "   Learning rate: 0.0003\n",
      "   Max learning rate: 0.001\n",
      "\n",
      "==================================================\n",
      "Epoch 1/20\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29ba672-fadf-4183-8945-951dc339eae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
